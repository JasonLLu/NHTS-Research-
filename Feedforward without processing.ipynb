{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "#tf.enable_eager_execution()\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "data = pd.read_csv(cwd + \"/encoded_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HHSIZE</th>\n",
       "      <th>HHVEHCNT</th>\n",
       "      <th>DRIVER_0</th>\n",
       "      <th>DRIVER_1</th>\n",
       "      <th>EDUC_1</th>\n",
       "      <th>EDUC_2</th>\n",
       "      <th>EDUC_3</th>\n",
       "      <th>EDUC_4</th>\n",
       "      <th>EDUC_5</th>\n",
       "      <th>URBANSIZE_1</th>\n",
       "      <th>URBANSIZE_2</th>\n",
       "      <th>URBANSIZE_3</th>\n",
       "      <th>URBANSIZE_4</th>\n",
       "      <th>URBANSIZE_5</th>\n",
       "      <th>URBANSIZE_6</th>\n",
       "      <th>URBRUR_1</th>\n",
       "      <th>URBRUR_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.359739</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.359739</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.359739</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.359739</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.359739</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     HHSIZE  HHVEHCNT  DRIVER_0  DRIVER_1  EDUC_1  EDUC_2  EDUC_3  EDUC_4  \\\n",
       "0  2.359739         3         0         1       0       0       1       0   \n",
       "1  2.359739         3         0         1       0       0       1       0   \n",
       "2  2.359739         3         0         1       0       0       1       0   \n",
       "3  2.359739         3         0         1       0       0       1       0   \n",
       "4  2.359739         3         0         1       0       1       0       0   \n",
       "\n",
       "   EDUC_5  URBANSIZE_1  URBANSIZE_2  URBANSIZE_3  URBANSIZE_4  URBANSIZE_5  \\\n",
       "0       0            1            0            0            0            0   \n",
       "1       0            1            0            0            0            0   \n",
       "2       0            1            0            0            0            0   \n",
       "3       0            1            0            0            0            0   \n",
       "4       0            1            0            0            0            0   \n",
       "\n",
       "   URBANSIZE_6  URBRUR_1  URBRUR_2  \n",
       "0            0         1         0  \n",
       "1            0         1         0  \n",
       "2            0         1         0  \n",
       "3            0         1         0  \n",
       "4            0         1         0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A utility method to create a tf.data dataset from a Pandas Dataframe\n",
    "def df_to_dataset(dataframe, shuffle=True, batch_size=200, target=\"HHVEHCNT\"):\n",
    "    dataframe = dataframe.copy()\n",
    "    labels = dataframe.pop(target)\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dataframe.values, labels.values))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "    ds = ds.batch(batch_size)\n",
    " \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 200\n",
    "# train_ds = df_to_dataset(train, batch_size=batch_size)\n",
    "# test_ds = df_to_dataset(test, batch_size=batch_size)\n",
    "# val_ds = df_to_dataset(val, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_np(dataframe,shuffle=True,batch_size=32,target=\"HHVEHCNT\"):\n",
    "    dataframe = dataframe.copy()\n",
    "    labels = dataframe.pop(target)\n",
    "    return dataframe.values, labels.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y = df_to_np(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(781831, 16)\n",
      "(781831,)\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape)\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 625464 samples, validate on 156367 samples\n",
      "Epoch 1/5\n",
      "471200/625464 [=====================>........] - ETA: 4s - loss: 0.9155 - accuracy: 0.5870"
     ]
    }
   ],
   "source": [
    "# model = tf.keras.Sequential()\n",
    "# model.add(tf.keras.layers.Dense(200, input_dim=16, activation=\"relu\"))\n",
    "# model.add(tf.keras.layers.Dense(200, input_dim=16, activation=\"relu\"))\n",
    "# model.add(tf.keras.layers.Dense(4))\n",
    "# model.add(tf.keras.layers.Activation(\"softmax\"))\n",
    "\n",
    "# model.compile(optimizer='adam',\n",
    "#               loss='sparse_categorical_crossentropy',\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# model.fit(x=train_np, y = train_labels_np, epochs=10,batch_size = 6000)\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(128,activation=\"relu\"),\n",
    "  tf.keras.layers.Dense(128),\n",
    "  #tf.keras.layers.Dropout(0.5),\n",
    "  tf.keras.layers.Dense(128),\n",
    "  #tf.keras.layers.Dropout(0.5),\n",
    "  tf.keras.layers.Dense(128),\n",
    "  tf.keras.layers.Dense(64,activation=\"relu\"),\n",
    "  tf.keras.layers.Dense(4,activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x=train_X, y = train_y,epochs=5, batch_size = 100, validation_split=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
