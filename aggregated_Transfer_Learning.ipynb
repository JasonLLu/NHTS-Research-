{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "#tf.enable_eager_execution()\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('encodedStates.pickle', 'rb') as handle:\n",
    "    data = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_np(dataframe,shuffle=True,batch_size=32,target=\"HHVEHCNT\"):\n",
    "    dataframe = dataframe.copy()\n",
    "    labels = dataframe.pop(target)\n",
    "    return dataframe.values, labels.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransferLearn:\n",
    "    \n",
    "    def __init__(self, fromStateData, toStateData, layers_to_transfer, verbose):\n",
    "        self.data = data\n",
    "        self.fromState = fromStateData\n",
    "        self.toState = toStateData\n",
    "        self.layers_to_transfer = layers_to_transfer\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        self.fromModelWeights = None\n",
    "        \n",
    "        self.train_X_from, self.train_y_from = df_to_np(fromStateData)\n",
    "        self.train_X_to, self.train_y_to = df_to_np(toStateData)\n",
    "    \n",
    "    #Get the weights from model built on toStateData\n",
    "    def getFromModelWeights(self, batch_size=100, validation_split=0.2, epochs=5):\n",
    "        train_X_from = self.train_X_from.copy()\n",
    "        train_y_from = self.train_y_from.copy()\n",
    "        model = tf.keras.Sequential([\n",
    "          tf.keras.layers.Dense(128,activation=\"relu\"),\n",
    "          tf.keras.layers.Dense(128),\n",
    "          tf.keras.layers.Dense(128),\n",
    "          tf.keras.layers.Dense(128),\n",
    "          tf.keras.layers.Dense(64,activation=\"relu\"),\n",
    "          tf.keras.layers.Dense(4,activation=\"softmax\")\n",
    "        ])\n",
    "        \n",
    "        model.compile(optimizer='adam',\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        model.fit(x=train_X_from, y = train_y_from,epochs=5, batch_size = batch_size, validation_split=validation_split, shuffle=True, verbose=self.verbose)\n",
    "        \n",
    "        weights = []\n",
    "        for i in range(0,self.layers_to_transfer):\n",
    "            weights.append(model.layers[i].get_weights())\n",
    "        return weights\n",
    "    \n",
    "    def transfer(self, trainable=True, batch_size=100, validation_split=0.2, epochs=5):\n",
    "        train_X_to = self.train_X_to.copy()\n",
    "        train_y_to = self.train_y_to.copy()\n",
    "        weights = self.getFromModelWeights()\n",
    "        print(\"*****weights obtained from fromStateData*****\")\n",
    "        \n",
    "        print(\"Transferring\")\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(128,activation=\"relu\", weights=weights[0], trainable=trainable))\n",
    "        for i in range(1,self.layers_to_transfer):\n",
    "            model.add(tf.keras.layers.Dense(128, weights=weights[i], trainable=trainable))\n",
    "        for i in range(4-self.layers_to_transfer,4):\n",
    "            model.add(tf.keras.layers.Dense(128))\n",
    "        model.add(tf.keras.layers.Dense(64,activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.Dense(4,activation=\"softmax\"))\n",
    "\n",
    "        \n",
    "        model.compile(optimizer='adam',\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "        print(\"what the fuck\", train_X_to.shape)\n",
    "        history = model.fit(x=train_X_to, y = train_y_to, epochs=epochs, batch_size = batch_size, validation_split=validation_split, shuffle=True,verbose=self.verbose)\n",
    "        val_acc = history.history[\"val_accuracy\"][-1]\n",
    "        print(\"*****Transferring done*****\", \"Trainable:\", trainable)\n",
    "        return model, val_acc\n",
    "    \n",
    "    \n",
    "    def benchmark(self, batch_size=100, validation_split=0.2, epochs=5):\n",
    "        train_X_to = self.train_X_to.copy()\n",
    "        train_y_to = self.train_y_to.copy()\n",
    "        print(\"*****Training Benchmark Model*****\")\n",
    "        model = tf.keras.Sequential([\n",
    "          tf.keras.layers.Dense(128,activation=\"relu\"),\n",
    "          tf.keras.layers.Dense(128),\n",
    "          tf.keras.layers.Dense(128),\n",
    "          tf.keras.layers.Dense(128),\n",
    "          tf.keras.layers.Dense(64,activation=\"relu\"),\n",
    "          tf.keras.layers.Dense(4,activation=\"softmax\")\n",
    "        ])\n",
    "        \n",
    "        model.compile(optimizer='adam',\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        history = model.fit(x=train_X_to, y = train_y_to,epochs=5, batch_size = batch_size, validation_split=validation_split, shuffle=True,verbose=self.verbose)\n",
    "        val_acc = history.history[\"val_accuracy\"][-1]\n",
    "        print(\"*****Training Benchmark Model Done*****\")\n",
    "        return model, val_acc\n",
    "    \n",
    "    def compare(self):\n",
    "        benchmark_model, benchmark_acc = self.benchmark()\n",
    "        frozenTransfer_model, frozenTransfer_acc = self.transfer(trainable=False)\n",
    "        unfrozenTransfer_model, unfrozenTransfer_acc = self.transfer(trainable=True)\n",
    "        \n",
    "        return (benchmark_acc-frozenTransfer_acc, benchmark_acc-unfrozenTransfer_acc)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Training Benchmark Model*****\n",
      "Train on 81690 samples, validate on 20423 samples\n",
      "Epoch 1/5\n",
      "81690/81690 [==============================] - 4s 50us/sample - loss: 0.9421 - accuracy: 0.5814 - val_loss: 0.9457 - val_accuracy: 0.5875\n",
      "Epoch 2/5\n",
      "81690/81690 [==============================] - 3s 37us/sample - loss: 0.9227 - accuracy: 0.5923 - val_loss: 0.9479 - val_accuracy: 0.5964\n",
      "Epoch 3/5\n",
      "81690/81690 [==============================] - 3s 35us/sample - loss: 0.9183 - accuracy: 0.5953 - val_loss: 0.9483 - val_accuracy: 0.5852\n",
      "Epoch 4/5\n",
      "81690/81690 [==============================] - 3s 35us/sample - loss: 0.9160 - accuracy: 0.5964 - val_loss: 0.9530 - val_accuracy: 0.5975\n",
      "Epoch 5/5\n",
      "81690/81690 [==============================] - 3s 35us/sample - loss: 0.9141 - accuracy: 0.5981 - val_loss: 0.9518 - val_accuracy: 0.5874\n",
      "*****Training Benchmark Model Done*****\n",
      "Train on 2568 samples, validate on 643 samples\n",
      "Epoch 1/5\n",
      "2568/2568 [==============================] - 1s 314us/sample - loss: 1.0717 - accuracy: 0.5308 - val_loss: 1.0745 - val_accuracy: 0.5552\n",
      "Epoch 2/5\n",
      "2568/2568 [==============================] - 0s 45us/sample - loss: 0.8517 - accuracy: 0.6745 - val_loss: 1.0243 - val_accuracy: 0.5754\n",
      "Epoch 3/5\n",
      "2568/2568 [==============================] - 0s 44us/sample - loss: 0.7951 - accuracy: 0.6939 - val_loss: 0.9816 - val_accuracy: 0.6096\n",
      "Epoch 4/5\n",
      "2568/2568 [==============================] - 0s 45us/sample - loss: 0.7864 - accuracy: 0.6908 - val_loss: 0.9976 - val_accuracy: 0.6003\n",
      "Epoch 5/5\n",
      "2568/2568 [==============================] - 0s 42us/sample - loss: 0.7476 - accuracy: 0.6982 - val_loss: 1.0685 - val_accuracy: 0.5708\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "what the fuck (102113, 16)\n",
      "Train on 81690 samples, validate on 20423 samples\n",
      "Epoch 1/5\n",
      "81690/81690 [==============================] - 3s 38us/sample - loss: 0.9408 - accuracy: 0.5832 - val_loss: 0.9574 - val_accuracy: 0.5899\n",
      "Epoch 2/5\n",
      "81690/81690 [==============================] - 3s 33us/sample - loss: 0.9232 - accuracy: 0.5944 - val_loss: 0.9554 - val_accuracy: 0.5937\n",
      "Epoch 3/5\n",
      "81690/81690 [==============================] - 3s 32us/sample - loss: 0.9206 - accuracy: 0.5953 - val_loss: 0.9437 - val_accuracy: 0.5905\n",
      "Epoch 4/5\n",
      "81690/81690 [==============================] - 3s 33us/sample - loss: 0.9184 - accuracy: 0.5965 - val_loss: 0.9456 - val_accuracy: 0.5975\n",
      "Epoch 5/5\n",
      "81690/81690 [==============================] - 3s 32us/sample - loss: 0.9172 - accuracy: 0.5962 - val_loss: 0.9452 - val_accuracy: 0.5948\n",
      "*****Transferring done***** Trainable: False\n",
      "Train on 2568 samples, validate on 643 samples\n",
      "Epoch 1/5\n",
      "2568/2568 [==============================] - 1s 262us/sample - loss: 1.0669 - accuracy: 0.5460 - val_loss: 1.0568 - val_accuracy: 0.5677\n",
      "Epoch 2/5\n",
      "2568/2568 [==============================] - 0s 45us/sample - loss: 0.8579 - accuracy: 0.6780 - val_loss: 1.0552 - val_accuracy: 0.5505\n",
      "Epoch 3/5\n",
      "2568/2568 [==============================] - 0s 49us/sample - loss: 0.8112 - accuracy: 0.6967 - val_loss: 1.0452 - val_accuracy: 0.5599\n",
      "Epoch 4/5\n",
      "2568/2568 [==============================] - 0s 43us/sample - loss: 0.7792 - accuracy: 0.6904 - val_loss: 1.0931 - val_accuracy: 0.5568\n",
      "Epoch 5/5\n",
      "2568/2568 [==============================] - 0s 43us/sample - loss: 0.7595 - accuracy: 0.7002 - val_loss: 1.0788 - val_accuracy: 0.5599\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "what the fuck (102113, 16)\n",
      "Train on 81690 samples, validate on 20423 samples\n",
      "Epoch 1/5\n",
      "81690/81690 [==============================] - 4s 47us/sample - loss: 0.9383 - accuracy: 0.5841 - val_loss: 0.9531 - val_accuracy: 0.5957\n",
      "Epoch 2/5\n",
      "81690/81690 [==============================] - 3s 40us/sample - loss: 0.9227 - accuracy: 0.5932 - val_loss: 0.9454 - val_accuracy: 0.5898\n",
      "Epoch 3/5\n",
      "81690/81690 [==============================] - 3s 37us/sample - loss: 0.9186 - accuracy: 0.5948 - val_loss: 0.9449 - val_accuracy: 0.5890\n",
      "Epoch 4/5\n",
      "81690/81690 [==============================] - 3s 37us/sample - loss: 0.9157 - accuracy: 0.5967 - val_loss: 0.9391 - val_accuracy: 0.5942\n",
      "Epoch 5/5\n",
      "81690/81690 [==============================] - 3s 35us/sample - loss: 0.9146 - accuracy: 0.5975 - val_loss: 0.9452 - val_accuracy: 0.6001\n",
      "*****Transferring done***** Trainable: True\n"
     ]
    }
   ],
   "source": [
    "MA_to_CA = TransferLearn(fromStateData = data[\"MA\"], toStateData = data[\"NY\"], layers_to_transfer=2, verbose = 1)\n",
    "compareMAandCA = MA_to_CA.compare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.00092953444, 0.014359415)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compareMAandCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['NC', 'WI', 'NY', 'MD', 'PA', 'CA', 'TX', 'AZ', 'WA', 'IL', 'KY', 'MT', 'IA', 'GA', 'ME', 'VA', 'SC', 'WV', 'FL', 'NH', 'MN', 'NE', 'AR', 'NJ', 'SD', 'NM', 'OK', 'MI', 'VT', 'ID', 'DE', 'MA', 'WY', 'CO', 'IN', 'AL', 'TN', 'HI', 'AK', 'OH', 'RI', 'LA', 'OR', 'KS', 'UT', 'MO', 'DC', 'NV', 'ND', 'MS', 'CT'])\n"
     ]
    }
   ],
   "source": [
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = [\"MA\", \"CA\", \"NY\"]\n",
    "I,J = len(states), len(states)\n",
    "similarity_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing MA MA\n",
      "Processing MA CA\n",
      "*****Training Benchmark Model*****\n",
      "*****Training Benchmark Model Done*****\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: False\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: True\n",
      "Processing MA NY\n",
      "*****Training Benchmark Model*****\n",
      "*****Training Benchmark Model Done*****\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Layer weight shape (15, 128) not compatible with provided weight shape (16, 128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-cb60c9e8b374>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfromState\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtoState\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0mtransferLearner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransferLearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfromStateData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfromState\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoStateData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoState\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers_to_transfer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                 \u001b[0mfrozen_diff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munfrozen_diff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransferLearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0mfrozen_diff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munfrozen_diff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-b5226ce107b5>\u001b[0m in \u001b[0;36mcompare\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mbenchmark_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbenchmark_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbenchmark\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0mfrozenTransfer_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrozenTransfer_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0munfrozenTransfer_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munfrozenTransfer_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-b5226ce107b5>\u001b[0m in \u001b[0;36mtransfer\u001b[0;34m(self, trainable, batch_size, validation_split, epochs)\u001b[0m\n\u001b[1;32m     54\u001b[0m                       metrics=['accuracy'])\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_X_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_y_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"*****Transferring done*****\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Trainable:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tfenv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/anaconda3/envs/tfenv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m           distribution_strategy=strategy)\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tfenv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0mcheck_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m         steps=steps_per_epoch)\n\u001b[0m\u001b[1;32m    517\u001b[0m     (x, y, sample_weights,\n\u001b[1;32m    518\u001b[0m      \u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tfenv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2417\u001b[0m     \u001b[0;31m# First, we build the model on the fly if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2419\u001b[0;31m       \u001b[0mall_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_model_with_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2420\u001b[0m       \u001b[0mis_build_called\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2421\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tfenv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_build_model_with_inputs\u001b[0;34m(self, inputs, targets)\u001b[0m\n\u001b[1;32m   2620\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2621\u001b[0m       \u001b[0mcast_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2622\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2623\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mprocessed_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_dict_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tfenv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_set_inputs\u001b[0;34m(self, inputs, outputs, training)\u001b[0m\n\u001b[1;32m   2707\u001b[0m           \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2708\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2709\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2710\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2711\u001b[0m         \u001b[0;31m# This Model or a submodel is dynamic and hasn't overridden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tfenv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    840\u001b[0m                     not base_layer_utils.is_in_eager_or_tf_function()):\n\u001b[1;32m    841\u001b[0m                   \u001b[0;32mwith\u001b[0m \u001b[0mauto_control_deps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAutomaticControlDependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0macd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 842\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    843\u001b[0m                     \u001b[0;31m# Wrap Tensors in `outputs` in `tf.identity` to avoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m                     \u001b[0;31m# circular dependencies.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tfenv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m       \u001b[0;31m# `outputs` will be the inputs to the next layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tfenv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    815\u001b[0m           \u001b[0;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 817\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    818\u001b[0m           \u001b[0mcast_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tfenv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2146\u001b[0m     \u001b[0;31m# Optionally load weight values specified at layer instantiation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2147\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_initial_weights'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2148\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2149\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tfenv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mset_weights\u001b[0;34m(self, weights)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         raise ValueError('Layer weight shape ' + str(ref_shape) +\n\u001b[1;32m   1335\u001b[0m                          \u001b[0;34m' not compatible with '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m                          'provided weight shape ' + str(w.shape))\n\u001b[0m\u001b[1;32m   1337\u001b[0m       \u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Layer weight shape (15, 128) not compatible with provided weight shape (16, 128)"
     ]
    }
   ],
   "source": [
    "layers_to_transfer = 4\n",
    "similarity_list.append(np.zeros((2,I,J)))\n",
    "#We can only transfer at most 4 layers for now\n",
    "for n in range(1,layers_to_transfer + 1):\n",
    "    #n of IxJ matrices\n",
    "    similarity = np.zeros((2,I,J))\n",
    "    for r in range(I):\n",
    "        fromState = states[r]\n",
    "        for c in range(J):\n",
    "            toState = states[c]\n",
    "            print(\"Processing\", fromState, toState)\n",
    "            if fromState != toState:\n",
    "                transferLearner = TransferLearn(fromStateData = data[fromState], toStateData = data[toState], layers_to_transfer=n,verbose=0)\n",
    "                frozen_diff, unfrozen_diff = transferLearner.compare()\n",
    "            else:\n",
    "                frozen_diff, unfrozen_diff = 0, 0\n",
    "            similarity[0][r][c] = frozen_diff\n",
    "            similarity[1][r][c] = unfrozen_diff\n",
    "    print(similarity)\n",
    "    similarity_list.append(similarity)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
