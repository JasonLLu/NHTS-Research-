{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "#tf.enable_eager_execution()\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('encodedStates.pickle', 'rb') as handle:\n",
    "    data = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_np(dataframe,shuffle=True,batch_size=32,target=\"HHVEHCNT\"):\n",
    "    dataframe = dataframe.copy()\n",
    "    labels = dataframe.pop(target)\n",
    "    return dataframe.values, labels.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransferLearn:\n",
    "    \n",
    "    def __init__(self, fromState, toState, layers_to_transfer, verbose):\n",
    "        self.data = data\n",
    "        self.fromState = fromState\n",
    "        self.toState = toState\n",
    "        self.layers_to_transfer = layers_to_transfer\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        \n",
    "        self.train_X_from, self.train_y_from = None, None\n",
    "        self.train_X_to, self.train_y_to = None, None\n",
    "        self.fromModelWeights = None\n",
    "    \n",
    "    def initFromStateData(self, sample_size = None):\n",
    "        if sample_size:\n",
    "            self.train_X_from, self.train_y_from = df_to_np(data[self.fromState].sample(sample_size))\n",
    "            return self.train_X_from, self.train_y_from\n",
    "        else:\n",
    "            self.train_X_from, self.train_y_from = df_to_np(data[self.fromState])\n",
    "            return self.train_X_from, self.train_y_from\n",
    "    \n",
    "    def initToStateData(self, sample_size = None):\n",
    "        if sample_size:\n",
    "            self.train_X_to, self.train_y_to = df_to_np(data[self.toState].sample(sample_size))\n",
    "            return self.train_X_to, self.train_y_to\n",
    "        else:\n",
    "            self.train_X_to, self.train_y_to = df_to_np(data[self.toState])\n",
    "            return self.train_X_to, self.train_y_to\n",
    "    \n",
    "    #Get the weights from model built on toStateData\n",
    "    def getFromModelWeights(self, batch_size=100, validation_split=0.2, epochs=50):\n",
    "        train_X_from = self.train_X_from.copy()\n",
    "        train_y_from = self.train_y_from.copy()\n",
    "        model = tf.keras.Sequential([\n",
    "          tf.keras.layers.Dense(128,activation=\"relu\"),\n",
    "          tf.keras.layers.Dense(128),\n",
    "          tf.keras.layers.Dense(128),\n",
    "          tf.keras.layers.Dense(128),\n",
    "          tf.keras.layers.Dense(64,activation=\"relu\"),\n",
    "          tf.keras.layers.Dense(4,activation=\"softmax\")\n",
    "        ])\n",
    "        \n",
    "        model.compile(optimizer='adam',\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        model.fit(x=self.train_X_from, y = self.train_y_from,epochs=epochs, batch_size = batch_size, validation_split=validation_split, shuffle=True, verbose=self.verbose)\n",
    "        \n",
    "        weights = []\n",
    "        for i in range(0,self.layers_to_transfer):\n",
    "            weights.append(model.layers[i].get_weights())\n",
    "        self.fromModelWeights = weights\n",
    "        return self.fromModelWeights\n",
    "    \n",
    "    def transfer(self, trainable=True, batch_size=100, validation_split=0.2, epochs=50):\n",
    "        train_X_to = self.train_X_to.copy()\n",
    "        train_y_to = self.train_y_to.copy()\n",
    "        weights = self.fromModelWeights if self.fromModelWeights else self.getFromModelWeights()\n",
    "        print(\"*****weights obtained from fromStateData*****\")\n",
    "        \n",
    "        print(\"Transferring\")\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(128,activation=\"relu\", weights=weights[0], trainable=trainable))\n",
    "        for i in range(1,self.layers_to_transfer):\n",
    "            model.add(tf.keras.layers.Dense(128, weights=weights[i], trainable=trainable))\n",
    "        for i in range(4-self.layers_to_transfer,4):\n",
    "            model.add(tf.keras.layers.Dense(128))\n",
    "        model.add(tf.keras.layers.Dense(64,activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.Dense(4,activation=\"softmax\"))\n",
    "\n",
    "        \n",
    "        model.compile(optimizer='adam',\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "        history = model.fit(x=self.train_X_to, y = self.train_y_to, epochs=epochs, batch_size = batch_size, validation_split=validation_split, shuffle=True,verbose=self.verbose)\n",
    "        val_acc = history.history[\"val_accuracy\"][-1]\n",
    "        print(\"*****Transferring done*****\", \"Trainable:\", trainable)\n",
    "        return model, val_acc\n",
    "    \n",
    "    \n",
    "    def benchmark(self, batch_size=100, validation_split=0.2, epochs=50):\n",
    "        train_X_to = self.train_X_to.copy()\n",
    "        train_y_to = self.train_y_to.copy()\n",
    "        print(\"*****Training Benchmark Model*****\")\n",
    "        model = tf.keras.Sequential([\n",
    "          tf.keras.layers.Dense(128,activation=\"relu\"),\n",
    "          tf.keras.layers.Dense(128),\n",
    "          tf.keras.layers.Dense(128),\n",
    "          tf.keras.layers.Dense(128),\n",
    "          tf.keras.layers.Dense(64,activation=\"relu\"),\n",
    "          tf.keras.layers.Dense(4,activation=\"softmax\")\n",
    "        ])\n",
    "        \n",
    "        model.compile(optimizer='adam',\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        history = model.fit(x=self.train_X_to, y = self.train_y_to,epochs=epochs, batch_size = batch_size, validation_split=validation_split, shuffle=True,verbose=self.verbose)\n",
    "        val_acc = history.history[\"val_accuracy\"][-1]\n",
    "        print(\"*****Training Benchmark Model Done*****\")\n",
    "        return model, val_acc\n",
    "    \n",
    "    def compare(self):\n",
    "        benchmark_model, benchmark_acc = self.benchmark()\n",
    "        frozenTransfer_model, frozenTransfer_acc = self.transfer(trainable=False)\n",
    "        unfrozenTransfer_model, unfrozenTransfer_acc = self.transfer(trainable=True)\n",
    "        \n",
    "        return (benchmark_acc-frozenTransfer_acc, benchmark_acc-unfrozenTransfer_acc)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Training Benchmark Model*****\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/50\n",
      "400/400 [==============================] - 1s 1ms/sample - loss: 1.2483 - accuracy: 0.4050 - val_loss: 1.0759 - val_accuracy: 0.4400\n",
      "Epoch 2/50\n",
      "400/400 [==============================] - 0s 93us/sample - loss: 1.1213 - accuracy: 0.4800 - val_loss: 1.0170 - val_accuracy: 0.4900\n",
      "Epoch 3/50\n",
      "400/400 [==============================] - 0s 117us/sample - loss: 1.0514 - accuracy: 0.5025 - val_loss: 0.9635 - val_accuracy: 0.4800\n",
      "Epoch 4/50\n",
      "400/400 [==============================] - 0s 88us/sample - loss: 1.0078 - accuracy: 0.5100 - val_loss: 0.9597 - val_accuracy: 0.4900\n",
      "Epoch 5/50\n",
      "400/400 [==============================] - 0s 140us/sample - loss: 0.9579 - accuracy: 0.5750 - val_loss: 0.9398 - val_accuracy: 0.5200\n",
      "Epoch 6/50\n",
      "400/400 [==============================] - 0s 126us/sample - loss: 0.9413 - accuracy: 0.5600 - val_loss: 0.9533 - val_accuracy: 0.5000\n",
      "Epoch 7/50\n",
      "400/400 [==============================] - 0s 148us/sample - loss: 0.9264 - accuracy: 0.5900 - val_loss: 0.9538 - val_accuracy: 0.5300\n",
      "Epoch 8/50\n",
      "400/400 [==============================] - 0s 123us/sample - loss: 0.9155 - accuracy: 0.5875 - val_loss: 0.9396 - val_accuracy: 0.5400\n",
      "Epoch 9/50\n",
      "400/400 [==============================] - 0s 118us/sample - loss: 0.8947 - accuracy: 0.6125 - val_loss: 0.9605 - val_accuracy: 0.5000\n",
      "Epoch 10/50\n",
      "400/400 [==============================] - 0s 126us/sample - loss: 0.8851 - accuracy: 0.6150 - val_loss: 0.9420 - val_accuracy: 0.5000\n",
      "Epoch 11/50\n",
      "400/400 [==============================] - 0s 97us/sample - loss: 0.8748 - accuracy: 0.5800 - val_loss: 0.9458 - val_accuracy: 0.5000\n",
      "Epoch 12/50\n",
      "400/400 [==============================] - 0s 82us/sample - loss: 0.8634 - accuracy: 0.6250 - val_loss: 0.9395 - val_accuracy: 0.5200\n",
      "Epoch 13/50\n",
      "400/400 [==============================] - 0s 76us/sample - loss: 0.8505 - accuracy: 0.6225 - val_loss: 0.9423 - val_accuracy: 0.5200\n",
      "Epoch 14/50\n",
      "400/400 [==============================] - 0s 76us/sample - loss: 0.8438 - accuracy: 0.6175 - val_loss: 0.9260 - val_accuracy: 0.5200\n",
      "Epoch 15/50\n",
      "400/400 [==============================] - 0s 89us/sample - loss: 0.8331 - accuracy: 0.6275 - val_loss: 0.9278 - val_accuracy: 0.5500\n",
      "Epoch 16/50\n",
      "400/400 [==============================] - 0s 79us/sample - loss: 0.8373 - accuracy: 0.6425 - val_loss: 0.9209 - val_accuracy: 0.5400\n",
      "Epoch 17/50\n",
      "400/400 [==============================] - 0s 94us/sample - loss: 0.8284 - accuracy: 0.6250 - val_loss: 0.9327 - val_accuracy: 0.5400\n",
      "Epoch 18/50\n",
      "400/400 [==============================] - 0s 100us/sample - loss: 0.8216 - accuracy: 0.6225 - val_loss: 0.9438 - val_accuracy: 0.5400\n",
      "Epoch 19/50\n",
      "400/400 [==============================] - 0s 73us/sample - loss: 0.8129 - accuracy: 0.6500 - val_loss: 0.9196 - val_accuracy: 0.5700\n",
      "Epoch 20/50\n",
      "400/400 [==============================] - 0s 74us/sample - loss: 0.8001 - accuracy: 0.6400 - val_loss: 0.9470 - val_accuracy: 0.5500\n",
      "Epoch 21/50\n",
      "400/400 [==============================] - 0s 88us/sample - loss: 0.8005 - accuracy: 0.6500 - val_loss: 0.9275 - val_accuracy: 0.5200\n",
      "Epoch 22/50\n",
      "400/400 [==============================] - 0s 73us/sample - loss: 0.7970 - accuracy: 0.6400 - val_loss: 0.9317 - val_accuracy: 0.5600\n",
      "Epoch 23/50\n",
      "400/400 [==============================] - 0s 73us/sample - loss: 0.7899 - accuracy: 0.6550 - val_loss: 0.9269 - val_accuracy: 0.5900\n",
      "Epoch 24/50\n",
      "400/400 [==============================] - 0s 95us/sample - loss: 0.7801 - accuracy: 0.6575 - val_loss: 0.9333 - val_accuracy: 0.5600\n",
      "Epoch 25/50\n",
      "400/400 [==============================] - 0s 125us/sample - loss: 0.7725 - accuracy: 0.6475 - val_loss: 0.9433 - val_accuracy: 0.5400\n",
      "Epoch 26/50\n",
      "400/400 [==============================] - 0s 99us/sample - loss: 0.7676 - accuracy: 0.6750 - val_loss: 0.9480 - val_accuracy: 0.5300\n",
      "Epoch 27/50\n",
      "400/400 [==============================] - 0s 110us/sample - loss: 0.7721 - accuracy: 0.6550 - val_loss: 0.9415 - val_accuracy: 0.5600\n",
      "Epoch 28/50\n",
      "400/400 [==============================] - 0s 129us/sample - loss: 0.7707 - accuracy: 0.6525 - val_loss: 0.9664 - val_accuracy: 0.5000\n",
      "Epoch 29/50\n",
      "400/400 [==============================] - 0s 106us/sample - loss: 0.7593 - accuracy: 0.6475 - val_loss: 0.9519 - val_accuracy: 0.5300\n",
      "Epoch 30/50\n",
      "400/400 [==============================] - 0s 80us/sample - loss: 0.7522 - accuracy: 0.6475 - val_loss: 0.9642 - val_accuracy: 0.5400\n",
      "Epoch 31/50\n",
      "400/400 [==============================] - 0s 79us/sample - loss: 0.7499 - accuracy: 0.6525 - val_loss: 0.9689 - val_accuracy: 0.5600\n",
      "Epoch 32/50\n",
      "400/400 [==============================] - 0s 101us/sample - loss: 0.7387 - accuracy: 0.6675 - val_loss: 0.9585 - val_accuracy: 0.5300\n",
      "Epoch 33/50\n",
      "400/400 [==============================] - 0s 99us/sample - loss: 0.7295 - accuracy: 0.6750 - val_loss: 0.9857 - val_accuracy: 0.5200\n",
      "Epoch 34/50\n",
      "400/400 [==============================] - 0s 109us/sample - loss: 0.7384 - accuracy: 0.6550 - val_loss: 0.9586 - val_accuracy: 0.5400\n",
      "Epoch 35/50\n",
      "400/400 [==============================] - 0s 119us/sample - loss: 0.7329 - accuracy: 0.6700 - val_loss: 0.9934 - val_accuracy: 0.5400\n",
      "Epoch 36/50\n",
      "400/400 [==============================] - 0s 114us/sample - loss: 0.7234 - accuracy: 0.6575 - val_loss: 0.9813 - val_accuracy: 0.5300\n",
      "Epoch 37/50\n",
      "400/400 [==============================] - 0s 119us/sample - loss: 0.7260 - accuracy: 0.6700 - val_loss: 0.9933 - val_accuracy: 0.5200\n",
      "Epoch 38/50\n",
      "400/400 [==============================] - 0s 106us/sample - loss: 0.7160 - accuracy: 0.6800 - val_loss: 1.0125 - val_accuracy: 0.5000\n",
      "Epoch 39/50\n",
      "400/400 [==============================] - 0s 82us/sample - loss: 0.7238 - accuracy: 0.6775 - val_loss: 0.9901 - val_accuracy: 0.5200\n",
      "Epoch 40/50\n",
      "400/400 [==============================] - 0s 93us/sample - loss: 0.7366 - accuracy: 0.6550 - val_loss: 1.0046 - val_accuracy: 0.5400\n",
      "Epoch 41/50\n",
      "400/400 [==============================] - 0s 108us/sample - loss: 0.7313 - accuracy: 0.6575 - val_loss: 1.0454 - val_accuracy: 0.5000\n",
      "Epoch 42/50\n",
      "400/400 [==============================] - 0s 124us/sample - loss: 0.7249 - accuracy: 0.6675 - val_loss: 1.0288 - val_accuracy: 0.5300\n",
      "Epoch 43/50\n",
      "400/400 [==============================] - 0s 191us/sample - loss: 0.7035 - accuracy: 0.6900 - val_loss: 1.0276 - val_accuracy: 0.5000\n",
      "Epoch 44/50\n",
      "400/400 [==============================] - 0s 127us/sample - loss: 0.7370 - accuracy: 0.6425 - val_loss: 1.0338 - val_accuracy: 0.5100\n",
      "Epoch 45/50\n",
      "400/400 [==============================] - 0s 159us/sample - loss: 0.7255 - accuracy: 0.6375 - val_loss: 1.0385 - val_accuracy: 0.4700\n",
      "Epoch 46/50\n",
      "400/400 [==============================] - 0s 146us/sample - loss: 0.7311 - accuracy: 0.6550 - val_loss: 1.0030 - val_accuracy: 0.5300\n",
      "Epoch 47/50\n",
      "400/400 [==============================] - 0s 106us/sample - loss: 0.6974 - accuracy: 0.6650 - val_loss: 1.1021 - val_accuracy: 0.4800\n",
      "Epoch 48/50\n",
      "400/400 [==============================] - 0s 74us/sample - loss: 0.6957 - accuracy: 0.6625 - val_loss: 1.0391 - val_accuracy: 0.5400\n",
      "Epoch 49/50\n",
      "400/400 [==============================] - 0s 84us/sample - loss: 0.6869 - accuracy: 0.6875 - val_loss: 1.0512 - val_accuracy: 0.5000\n",
      "Epoch 50/50\n",
      "400/400 [==============================] - 0s 126us/sample - loss: 0.6860 - accuracy: 0.6825 - val_loss: 1.0887 - val_accuracy: 0.5200\n",
      "*****Training Benchmark Model Done*****\n",
      "Train on 2568 samples, validate on 643 samples\n",
      "Epoch 1/50\n",
      "2568/2568 [==============================] - 1s 287us/sample - loss: 1.0597 - accuracy: 0.5588 - val_loss: 1.1045 - val_accuracy: 0.5008\n",
      "Epoch 2/50\n",
      "2568/2568 [==============================] - 0s 45us/sample - loss: 0.8702 - accuracy: 0.6616 - val_loss: 1.1006 - val_accuracy: 0.5505\n",
      "Epoch 3/50\n",
      "2568/2568 [==============================] - 0s 44us/sample - loss: 0.7999 - accuracy: 0.6889 - val_loss: 1.0495 - val_accuracy: 0.5770\n",
      "Epoch 4/50\n",
      "2568/2568 [==============================] - 0s 46us/sample - loss: 0.7626 - accuracy: 0.7025 - val_loss: 1.1477 - val_accuracy: 0.5505\n",
      "Epoch 5/50\n",
      "2568/2568 [==============================] - 0s 82us/sample - loss: 0.7409 - accuracy: 0.7079 - val_loss: 1.1983 - val_accuracy: 0.5708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50\n",
      "2568/2568 [==============================] - 0s 60us/sample - loss: 0.7185 - accuracy: 0.7134 - val_loss: 1.2106 - val_accuracy: 0.5645\n",
      "Epoch 7/50\n",
      "2568/2568 [==============================] - 0s 49us/sample - loss: 0.6975 - accuracy: 0.7188 - val_loss: 1.2404 - val_accuracy: 0.5474\n",
      "Epoch 8/50\n",
      "2568/2568 [==============================] - 0s 81us/sample - loss: 0.6808 - accuracy: 0.7216 - val_loss: 1.2812 - val_accuracy: 0.5365\n",
      "Epoch 9/50\n",
      "2568/2568 [==============================] - 0s 53us/sample - loss: 0.6933 - accuracy: 0.7130 - val_loss: 1.3031 - val_accuracy: 0.5179\n",
      "Epoch 10/50\n",
      "2568/2568 [==============================] - 0s 51us/sample - loss: 0.6799 - accuracy: 0.7204 - val_loss: 1.3797 - val_accuracy: 0.5132\n",
      "Epoch 11/50\n",
      "2568/2568 [==============================] - 0s 59us/sample - loss: 0.6704 - accuracy: 0.7247 - val_loss: 1.4185 - val_accuracy: 0.5334\n",
      "Epoch 12/50\n",
      "2568/2568 [==============================] - 0s 52us/sample - loss: 0.6584 - accuracy: 0.7294 - val_loss: 1.3378 - val_accuracy: 0.5319\n",
      "Epoch 13/50\n",
      "2568/2568 [==============================] - 0s 62us/sample - loss: 0.6572 - accuracy: 0.7294 - val_loss: 1.4173 - val_accuracy: 0.5132\n",
      "Epoch 14/50\n",
      "2568/2568 [==============================] - 0s 48us/sample - loss: 0.6444 - accuracy: 0.7368 - val_loss: 1.4726 - val_accuracy: 0.5241\n",
      "Epoch 15/50\n",
      "2568/2568 [==============================] - 0s 58us/sample - loss: 0.6551 - accuracy: 0.7274 - val_loss: 1.5790 - val_accuracy: 0.5132\n",
      "Epoch 16/50\n",
      "2568/2568 [==============================] - 0s 44us/sample - loss: 0.6469 - accuracy: 0.7410 - val_loss: 1.5363 - val_accuracy: 0.5101\n",
      "Epoch 17/50\n",
      "2568/2568 [==============================] - 0s 40us/sample - loss: 0.6455 - accuracy: 0.7344 - val_loss: 1.7095 - val_accuracy: 0.5241\n",
      "Epoch 18/50\n",
      "2568/2568 [==============================] - 0s 39us/sample - loss: 0.6379 - accuracy: 0.7290 - val_loss: 1.5901 - val_accuracy: 0.5257\n",
      "Epoch 19/50\n",
      "2568/2568 [==============================] - 0s 40us/sample - loss: 0.6368 - accuracy: 0.7442 - val_loss: 1.6947 - val_accuracy: 0.5086\n",
      "Epoch 20/50\n",
      "2568/2568 [==============================] - 0s 37us/sample - loss: 0.6344 - accuracy: 0.7395 - val_loss: 1.7156 - val_accuracy: 0.5117\n",
      "Epoch 21/50\n",
      "2568/2568 [==============================] - 0s 39us/sample - loss: 0.6321 - accuracy: 0.7371 - val_loss: 1.7470 - val_accuracy: 0.4759\n",
      "Epoch 22/50\n",
      "2568/2568 [==============================] - 0s 43us/sample - loss: 0.6441 - accuracy: 0.7309 - val_loss: 1.6016 - val_accuracy: 0.5288\n",
      "Epoch 23/50\n",
      "2568/2568 [==============================] - 0s 41us/sample - loss: 0.6316 - accuracy: 0.7387 - val_loss: 1.8042 - val_accuracy: 0.5070\n",
      "Epoch 24/50\n",
      "2568/2568 [==============================] - 0s 39us/sample - loss: 0.6243 - accuracy: 0.7469 - val_loss: 1.7628 - val_accuracy: 0.5086\n",
      "Epoch 25/50\n",
      "2568/2568 [==============================] - 0s 37us/sample - loss: 0.6420 - accuracy: 0.7371 - val_loss: 1.7811 - val_accuracy: 0.5008\n",
      "Epoch 26/50\n",
      "2568/2568 [==============================] - 0s 38us/sample - loss: 0.6266 - accuracy: 0.7395 - val_loss: 1.7056 - val_accuracy: 0.5008\n",
      "Epoch 27/50\n",
      "2568/2568 [==============================] - 0s 37us/sample - loss: 0.6330 - accuracy: 0.7352 - val_loss: 1.7429 - val_accuracy: 0.5086\n",
      "Epoch 28/50\n",
      "2568/2568 [==============================] - 0s 39us/sample - loss: 0.6269 - accuracy: 0.7492 - val_loss: 1.7975 - val_accuracy: 0.4961\n",
      "Epoch 29/50\n",
      "2568/2568 [==============================] - 0s 40us/sample - loss: 0.6278 - accuracy: 0.7422 - val_loss: 1.7684 - val_accuracy: 0.4868\n",
      "Epoch 30/50\n",
      "2568/2568 [==============================] - 0s 41us/sample - loss: 0.6320 - accuracy: 0.7344 - val_loss: 1.7485 - val_accuracy: 0.4961\n",
      "Epoch 31/50\n",
      "2568/2568 [==============================] - 0s 40us/sample - loss: 0.6241 - accuracy: 0.7438 - val_loss: 1.9580 - val_accuracy: 0.5117\n",
      "Epoch 32/50\n",
      "2568/2568 [==============================] - 0s 41us/sample - loss: 0.6242 - accuracy: 0.7422 - val_loss: 1.8289 - val_accuracy: 0.4961\n",
      "Epoch 33/50\n",
      "2568/2568 [==============================] - 0s 39us/sample - loss: 0.6249 - accuracy: 0.7399 - val_loss: 1.7449 - val_accuracy: 0.4961\n",
      "Epoch 34/50\n",
      "2568/2568 [==============================] - 0s 39us/sample - loss: 0.6208 - accuracy: 0.7445 - val_loss: 1.9021 - val_accuracy: 0.4961\n",
      "Epoch 35/50\n",
      "2568/2568 [==============================] - 0s 40us/sample - loss: 0.6198 - accuracy: 0.7414 - val_loss: 1.8560 - val_accuracy: 0.5023\n",
      "Epoch 36/50\n",
      "2568/2568 [==============================] - 0s 41us/sample - loss: 0.6130 - accuracy: 0.7465 - val_loss: 1.8196 - val_accuracy: 0.4961\n",
      "Epoch 37/50\n",
      "2568/2568 [==============================] - 0s 40us/sample - loss: 0.6187 - accuracy: 0.7504 - val_loss: 1.8011 - val_accuracy: 0.4961\n",
      "Epoch 38/50\n",
      "2568/2568 [==============================] - 0s 41us/sample - loss: 0.6299 - accuracy: 0.7453 - val_loss: 1.9344 - val_accuracy: 0.5039\n",
      "Epoch 39/50\n",
      "2568/2568 [==============================] - 0s 40us/sample - loss: 0.6231 - accuracy: 0.7461 - val_loss: 1.7306 - val_accuracy: 0.5039\n",
      "Epoch 40/50\n",
      "2568/2568 [==============================] - 0s 41us/sample - loss: 0.6226 - accuracy: 0.7422 - val_loss: 1.9199 - val_accuracy: 0.4961\n",
      "Epoch 41/50\n",
      "2568/2568 [==============================] - 0s 44us/sample - loss: 0.6127 - accuracy: 0.7469 - val_loss: 1.9410 - val_accuracy: 0.5101\n",
      "Epoch 42/50\n",
      "2568/2568 [==============================] - 0s 40us/sample - loss: 0.6130 - accuracy: 0.7496 - val_loss: 1.9064 - val_accuracy: 0.4961\n",
      "Epoch 43/50\n",
      "2568/2568 [==============================] - 0s 38us/sample - loss: 0.6174 - accuracy: 0.7457 - val_loss: 1.9132 - val_accuracy: 0.5101\n",
      "Epoch 44/50\n",
      "2568/2568 [==============================] - 0s 38us/sample - loss: 0.6196 - accuracy: 0.7461 - val_loss: 1.8391 - val_accuracy: 0.4992\n",
      "Epoch 45/50\n",
      "2568/2568 [==============================] - 0s 41us/sample - loss: 0.6180 - accuracy: 0.7418 - val_loss: 1.8699 - val_accuracy: 0.4961\n",
      "Epoch 46/50\n",
      "2568/2568 [==============================] - 0s 38us/sample - loss: 0.6122 - accuracy: 0.7469 - val_loss: 1.9509 - val_accuracy: 0.4992\n",
      "Epoch 47/50\n",
      "2568/2568 [==============================] - 0s 44us/sample - loss: 0.6214 - accuracy: 0.7481 - val_loss: 1.8462 - val_accuracy: 0.4883\n",
      "Epoch 48/50\n",
      "2568/2568 [==============================] - 0s 40us/sample - loss: 0.6164 - accuracy: 0.7449 - val_loss: 1.8384 - val_accuracy: 0.4635\n",
      "Epoch 49/50\n",
      "2568/2568 [==============================] - 0s 40us/sample - loss: 0.6154 - accuracy: 0.7403 - val_loss: 1.9696 - val_accuracy: 0.5148\n",
      "Epoch 50/50\n",
      "2568/2568 [==============================] - 0s 41us/sample - loss: 0.6129 - accuracy: 0.7481 - val_loss: 1.8054 - val_accuracy: 0.4961\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/50\n",
      "400/400 [==============================] - 0s 1ms/sample - loss: 1.3443 - accuracy: 0.3225 - val_loss: 1.1105 - val_accuracy: 0.5800\n",
      "Epoch 2/50\n",
      "400/400 [==============================] - 0s 74us/sample - loss: 1.1229 - accuracy: 0.5125 - val_loss: 0.9777 - val_accuracy: 0.6100\n",
      "Epoch 3/50\n",
      "400/400 [==============================] - 0s 66us/sample - loss: 1.0184 - accuracy: 0.5275 - val_loss: 0.9470 - val_accuracy: 0.5900\n",
      "Epoch 4/50\n",
      "400/400 [==============================] - 0s 69us/sample - loss: 0.9773 - accuracy: 0.5750 - val_loss: 0.9479 - val_accuracy: 0.5900\n",
      "Epoch 5/50\n",
      "400/400 [==============================] - 0s 71us/sample - loss: 0.9452 - accuracy: 0.5850 - val_loss: 0.9381 - val_accuracy: 0.5400\n",
      "Epoch 6/50\n",
      "400/400 [==============================] - 0s 69us/sample - loss: 0.9317 - accuracy: 0.5825 - val_loss: 0.9412 - val_accuracy: 0.5500\n",
      "Epoch 7/50\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.9095 - accuracy: 0.5975 - val_loss: 0.9620 - val_accuracy: 0.5300\n",
      "Epoch 8/50\n",
      "400/400 [==============================] - 0s 72us/sample - loss: 0.9077 - accuracy: 0.5800 - val_loss: 0.9566 - val_accuracy: 0.5600\n",
      "Epoch 9/50\n",
      "400/400 [==============================] - 0s 74us/sample - loss: 0.8942 - accuracy: 0.6225 - val_loss: 0.9262 - val_accuracy: 0.5400\n",
      "Epoch 10/50\n",
      "400/400 [==============================] - 0s 73us/sample - loss: 0.8891 - accuracy: 0.6175 - val_loss: 0.9295 - val_accuracy: 0.5400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.8740 - accuracy: 0.6225 - val_loss: 0.9600 - val_accuracy: 0.5000\n",
      "Epoch 12/50\n",
      "400/400 [==============================] - 0s 74us/sample - loss: 0.8735 - accuracy: 0.5700 - val_loss: 0.9422 - val_accuracy: 0.5400\n",
      "Epoch 13/50\n",
      "400/400 [==============================] - 0s 71us/sample - loss: 0.8648 - accuracy: 0.6300 - val_loss: 0.9269 - val_accuracy: 0.5500\n",
      "Epoch 14/50\n",
      "400/400 [==============================] - 0s 67us/sample - loss: 0.8649 - accuracy: 0.6325 - val_loss: 0.9377 - val_accuracy: 0.5300\n",
      "Epoch 15/50\n",
      "400/400 [==============================] - 0s 69us/sample - loss: 0.8521 - accuracy: 0.6375 - val_loss: 0.9421 - val_accuracy: 0.5400\n",
      "Epoch 16/50\n",
      "400/400 [==============================] - 0s 73us/sample - loss: 0.8465 - accuracy: 0.6375 - val_loss: 0.9320 - val_accuracy: 0.5400\n",
      "Epoch 17/50\n",
      "400/400 [==============================] - 0s 147us/sample - loss: 0.8418 - accuracy: 0.6400 - val_loss: 0.9343 - val_accuracy: 0.5400\n",
      "Epoch 18/50\n",
      "400/400 [==============================] - 0s 250us/sample - loss: 0.8382 - accuracy: 0.6400 - val_loss: 0.9351 - val_accuracy: 0.5300\n",
      "Epoch 19/50\n",
      "400/400 [==============================] - 0s 280us/sample - loss: 0.8363 - accuracy: 0.6325 - val_loss: 0.9399 - val_accuracy: 0.5300\n",
      "Epoch 20/50\n",
      "400/400 [==============================] - 0s 193us/sample - loss: 0.8329 - accuracy: 0.6325 - val_loss: 0.9260 - val_accuracy: 0.5500\n",
      "Epoch 21/50\n",
      "400/400 [==============================] - 0s 135us/sample - loss: 0.8280 - accuracy: 0.6325 - val_loss: 0.9509 - val_accuracy: 0.5400\n",
      "Epoch 22/50\n",
      "400/400 [==============================] - 0s 79us/sample - loss: 0.8237 - accuracy: 0.6350 - val_loss: 0.9384 - val_accuracy: 0.5300\n",
      "Epoch 23/50\n",
      "400/400 [==============================] - 0s 73us/sample - loss: 0.8165 - accuracy: 0.6500 - val_loss: 0.9406 - val_accuracy: 0.5400\n",
      "Epoch 24/50\n",
      "400/400 [==============================] - 0s 84us/sample - loss: 0.8204 - accuracy: 0.6250 - val_loss: 0.9370 - val_accuracy: 0.5300\n",
      "Epoch 25/50\n",
      "400/400 [==============================] - 0s 70us/sample - loss: 0.8109 - accuracy: 0.6450 - val_loss: 0.9422 - val_accuracy: 0.5600\n",
      "Epoch 26/50\n",
      "400/400 [==============================] - 0s 127us/sample - loss: 0.8130 - accuracy: 0.6250 - val_loss: 0.9392 - val_accuracy: 0.5600\n",
      "Epoch 27/50\n",
      "400/400 [==============================] - 0s 286us/sample - loss: 0.8081 - accuracy: 0.6300 - val_loss: 0.9561 - val_accuracy: 0.5100\n",
      "Epoch 28/50\n",
      "400/400 [==============================] - 0s 129us/sample - loss: 0.8054 - accuracy: 0.6475 - val_loss: 0.9476 - val_accuracy: 0.5400\n",
      "Epoch 29/50\n",
      "400/400 [==============================] - 0s 80us/sample - loss: 0.8013 - accuracy: 0.6525 - val_loss: 0.9400 - val_accuracy: 0.5500\n",
      "Epoch 30/50\n",
      "400/400 [==============================] - 0s 74us/sample - loss: 0.8055 - accuracy: 0.6425 - val_loss: 0.9683 - val_accuracy: 0.5300\n",
      "Epoch 31/50\n",
      "400/400 [==============================] - 0s 70us/sample - loss: 0.7990 - accuracy: 0.6500 - val_loss: 0.9393 - val_accuracy: 0.5400\n",
      "Epoch 32/50\n",
      "400/400 [==============================] - 0s 68us/sample - loss: 0.7970 - accuracy: 0.6300 - val_loss: 0.9391 - val_accuracy: 0.5300\n",
      "Epoch 33/50\n",
      "400/400 [==============================] - 0s 75us/sample - loss: 0.7900 - accuracy: 0.6375 - val_loss: 0.9684 - val_accuracy: 0.5300\n",
      "Epoch 34/50\n",
      "400/400 [==============================] - 0s 70us/sample - loss: 0.7837 - accuracy: 0.6550 - val_loss: 0.9525 - val_accuracy: 0.5200\n",
      "Epoch 35/50\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.7814 - accuracy: 0.6575 - val_loss: 0.9581 - val_accuracy: 0.5500\n",
      "Epoch 36/50\n",
      "400/400 [==============================] - 0s 75us/sample - loss: 0.7811 - accuracy: 0.6375 - val_loss: 0.9642 - val_accuracy: 0.5300\n",
      "Epoch 37/50\n",
      "400/400 [==============================] - 0s 78us/sample - loss: 0.7770 - accuracy: 0.6575 - val_loss: 0.9643 - val_accuracy: 0.5200\n",
      "Epoch 38/50\n",
      "400/400 [==============================] - 0s 99us/sample - loss: 0.7749 - accuracy: 0.6500 - val_loss: 0.9568 - val_accuracy: 0.5500\n",
      "Epoch 39/50\n",
      "400/400 [==============================] - 0s 97us/sample - loss: 0.7680 - accuracy: 0.6625 - val_loss: 0.9691 - val_accuracy: 0.5400\n",
      "Epoch 40/50\n",
      "400/400 [==============================] - 0s 82us/sample - loss: 0.7662 - accuracy: 0.6650 - val_loss: 0.9607 - val_accuracy: 0.5400\n",
      "Epoch 41/50\n",
      "400/400 [==============================] - 0s 93us/sample - loss: 0.7739 - accuracy: 0.6475 - val_loss: 0.9835 - val_accuracy: 0.5400\n",
      "Epoch 42/50\n",
      "400/400 [==============================] - 0s 106us/sample - loss: 0.7658 - accuracy: 0.6525 - val_loss: 0.9613 - val_accuracy: 0.5400\n",
      "Epoch 43/50\n",
      "400/400 [==============================] - 0s 122us/sample - loss: 0.7614 - accuracy: 0.6500 - val_loss: 0.9827 - val_accuracy: 0.5300\n",
      "Epoch 44/50\n",
      "400/400 [==============================] - 0s 96us/sample - loss: 0.7655 - accuracy: 0.6625 - val_loss: 0.9805 - val_accuracy: 0.5300\n",
      "Epoch 45/50\n",
      "400/400 [==============================] - 0s 92us/sample - loss: 0.7578 - accuracy: 0.6575 - val_loss: 0.9734 - val_accuracy: 0.5500\n",
      "Epoch 46/50\n",
      "400/400 [==============================] - 0s 70us/sample - loss: 0.7561 - accuracy: 0.6600 - val_loss: 0.9832 - val_accuracy: 0.5100\n",
      "Epoch 47/50\n",
      "400/400 [==============================] - 0s 74us/sample - loss: 0.7483 - accuracy: 0.6600 - val_loss: 0.9749 - val_accuracy: 0.5500\n",
      "Epoch 48/50\n",
      "400/400 [==============================] - 0s 70us/sample - loss: 0.7492 - accuracy: 0.6650 - val_loss: 0.9843 - val_accuracy: 0.5400\n",
      "Epoch 49/50\n",
      "400/400 [==============================] - 0s 67us/sample - loss: 0.7559 - accuracy: 0.6675 - val_loss: 1.0024 - val_accuracy: 0.5300\n",
      "Epoch 50/50\n",
      "400/400 [==============================] - 0s 67us/sample - loss: 0.7459 - accuracy: 0.6650 - val_loss: 0.9744 - val_accuracy: 0.5300\n",
      "*****Transferring done***** Trainable: False\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/50\n",
      "400/400 [==============================] - 1s 1ms/sample - loss: 1.2776 - accuracy: 0.3525 - val_loss: 1.0689 - val_accuracy: 0.4500\n",
      "Epoch 2/50\n",
      "400/400 [==============================] - 0s 70us/sample - loss: 1.0487 - accuracy: 0.4950 - val_loss: 0.9437 - val_accuracy: 0.5700\n",
      "Epoch 3/50\n",
      "400/400 [==============================] - 0s 75us/sample - loss: 0.9790 - accuracy: 0.5325 - val_loss: 0.9321 - val_accuracy: 0.5200\n",
      "Epoch 4/50\n",
      "400/400 [==============================] - 0s 76us/sample - loss: 0.9393 - accuracy: 0.5875 - val_loss: 0.9092 - val_accuracy: 0.5600\n",
      "Epoch 5/50\n",
      "400/400 [==============================] - 0s 71us/sample - loss: 0.9119 - accuracy: 0.5975 - val_loss: 0.9402 - val_accuracy: 0.5500\n",
      "Epoch 6/50\n",
      "400/400 [==============================] - 0s 71us/sample - loss: 0.8966 - accuracy: 0.6125 - val_loss: 0.9353 - val_accuracy: 0.5500\n",
      "Epoch 7/50\n",
      "400/400 [==============================] - 0s 68us/sample - loss: 0.8800 - accuracy: 0.6300 - val_loss: 0.9495 - val_accuracy: 0.5300\n",
      "Epoch 8/50\n",
      "400/400 [==============================] - 0s 70us/sample - loss: 0.8667 - accuracy: 0.6300 - val_loss: 0.9254 - val_accuracy: 0.5300\n",
      "Epoch 9/50\n",
      "400/400 [==============================] - 0s 99us/sample - loss: 0.8524 - accuracy: 0.6425 - val_loss: 0.9251 - val_accuracy: 0.5200\n",
      "Epoch 10/50\n",
      "400/400 [==============================] - 0s 75us/sample - loss: 0.8424 - accuracy: 0.6325 - val_loss: 0.9263 - val_accuracy: 0.5600\n",
      "Epoch 11/50\n",
      "400/400 [==============================] - 0s 75us/sample - loss: 0.8438 - accuracy: 0.6325 - val_loss: 0.9044 - val_accuracy: 0.5500\n",
      "Epoch 12/50\n",
      "400/400 [==============================] - 0s 75us/sample - loss: 0.8293 - accuracy: 0.6150 - val_loss: 0.9275 - val_accuracy: 0.5100\n",
      "Epoch 13/50\n",
      "400/400 [==============================] - 0s 77us/sample - loss: 0.8174 - accuracy: 0.6300 - val_loss: 0.9115 - val_accuracy: 0.5800\n",
      "Epoch 14/50\n",
      "400/400 [==============================] - 0s 78us/sample - loss: 0.8113 - accuracy: 0.6375 - val_loss: 0.9041 - val_accuracy: 0.5500\n",
      "Epoch 15/50\n",
      "400/400 [==============================] - 0s 81us/sample - loss: 0.8163 - accuracy: 0.6175 - val_loss: 0.8967 - val_accuracy: 0.5500\n",
      "Epoch 16/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 75us/sample - loss: 0.8059 - accuracy: 0.6400 - val_loss: 0.9210 - val_accuracy: 0.5700\n",
      "Epoch 17/50\n",
      "400/400 [==============================] - 0s 73us/sample - loss: 0.7935 - accuracy: 0.6425 - val_loss: 0.9197 - val_accuracy: 0.5200\n",
      "Epoch 18/50\n",
      "400/400 [==============================] - 0s 67us/sample - loss: 0.7855 - accuracy: 0.6425 - val_loss: 0.8958 - val_accuracy: 0.5400\n",
      "Epoch 19/50\n",
      "400/400 [==============================] - 0s 69us/sample - loss: 0.7755 - accuracy: 0.6525 - val_loss: 0.9277 - val_accuracy: 0.5500\n",
      "Epoch 20/50\n",
      "400/400 [==============================] - 0s 76us/sample - loss: 0.7707 - accuracy: 0.6575 - val_loss: 0.9134 - val_accuracy: 0.5400\n",
      "Epoch 21/50\n",
      "400/400 [==============================] - 0s 74us/sample - loss: 0.7646 - accuracy: 0.6375 - val_loss: 0.9405 - val_accuracy: 0.5400\n",
      "Epoch 22/50\n",
      "400/400 [==============================] - 0s 71us/sample - loss: 0.7656 - accuracy: 0.6350 - val_loss: 0.9401 - val_accuracy: 0.5500\n",
      "Epoch 23/50\n",
      "400/400 [==============================] - 0s 77us/sample - loss: 0.7559 - accuracy: 0.6600 - val_loss: 0.9415 - val_accuracy: 0.5200\n",
      "Epoch 24/50\n",
      "400/400 [==============================] - 0s 68us/sample - loss: 0.7531 - accuracy: 0.6425 - val_loss: 0.9238 - val_accuracy: 0.5700\n",
      "Epoch 25/50\n",
      "400/400 [==============================] - 0s 72us/sample - loss: 0.7474 - accuracy: 0.6600 - val_loss: 0.9452 - val_accuracy: 0.5500\n",
      "Epoch 26/50\n",
      "400/400 [==============================] - 0s 74us/sample - loss: 0.7389 - accuracy: 0.6700 - val_loss: 0.9592 - val_accuracy: 0.5400\n",
      "Epoch 27/50\n",
      "400/400 [==============================] - 0s 73us/sample - loss: 0.7384 - accuracy: 0.6650 - val_loss: 0.9587 - val_accuracy: 0.5400\n",
      "Epoch 28/50\n",
      "400/400 [==============================] - 0s 66us/sample - loss: 0.7393 - accuracy: 0.6625 - val_loss: 0.9570 - val_accuracy: 0.5500\n",
      "Epoch 29/50\n",
      "400/400 [==============================] - 0s 68us/sample - loss: 0.7407 - accuracy: 0.6675 - val_loss: 0.9491 - val_accuracy: 0.5300\n",
      "Epoch 30/50\n",
      "400/400 [==============================] - 0s 72us/sample - loss: 0.7325 - accuracy: 0.6600 - val_loss: 1.0034 - val_accuracy: 0.5600\n",
      "Epoch 31/50\n",
      "400/400 [==============================] - 0s 66us/sample - loss: 0.7296 - accuracy: 0.6725 - val_loss: 0.9713 - val_accuracy: 0.5200\n",
      "Epoch 32/50\n",
      "400/400 [==============================] - 0s 65us/sample - loss: 0.7180 - accuracy: 0.6825 - val_loss: 0.9966 - val_accuracy: 0.5200\n",
      "Epoch 33/50\n",
      "400/400 [==============================] - 0s 72us/sample - loss: 0.7168 - accuracy: 0.6750 - val_loss: 0.9972 - val_accuracy: 0.5200\n",
      "Epoch 34/50\n",
      "400/400 [==============================] - 0s 154us/sample - loss: 0.7077 - accuracy: 0.6625 - val_loss: 1.0099 - val_accuracy: 0.5100\n",
      "Epoch 35/50\n",
      "400/400 [==============================] - 0s 70us/sample - loss: 0.7130 - accuracy: 0.6675 - val_loss: 1.0111 - val_accuracy: 0.5300\n",
      "Epoch 36/50\n",
      "400/400 [==============================] - 0s 71us/sample - loss: 0.7057 - accuracy: 0.6825 - val_loss: 1.0114 - val_accuracy: 0.5400\n",
      "Epoch 37/50\n",
      "400/400 [==============================] - 0s 72us/sample - loss: 0.7305 - accuracy: 0.6475 - val_loss: 1.0222 - val_accuracy: 0.5400\n",
      "Epoch 38/50\n",
      "400/400 [==============================] - 0s 72us/sample - loss: 0.7154 - accuracy: 0.6700 - val_loss: 1.0148 - val_accuracy: 0.5300\n",
      "Epoch 39/50\n",
      "400/400 [==============================] - 0s 70us/sample - loss: 0.6941 - accuracy: 0.6825 - val_loss: 1.0666 - val_accuracy: 0.5300\n",
      "Epoch 40/50\n",
      "400/400 [==============================] - 0s 82us/sample - loss: 0.7009 - accuracy: 0.6875 - val_loss: 1.0321 - val_accuracy: 0.5400\n",
      "Epoch 41/50\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.6877 - accuracy: 0.6900 - val_loss: 1.0873 - val_accuracy: 0.5000\n",
      "Epoch 42/50\n",
      "400/400 [==============================] - 0s 72us/sample - loss: 0.6912 - accuracy: 0.6775 - val_loss: 1.0650 - val_accuracy: 0.5300\n",
      "Epoch 43/50\n",
      "400/400 [==============================] - 0s 71us/sample - loss: 0.6962 - accuracy: 0.6700 - val_loss: 1.0557 - val_accuracy: 0.5300\n",
      "Epoch 44/50\n",
      "400/400 [==============================] - 0s 72us/sample - loss: 0.6968 - accuracy: 0.6625 - val_loss: 1.0611 - val_accuracy: 0.5600\n",
      "Epoch 45/50\n",
      "400/400 [==============================] - 0s 72us/sample - loss: 0.6919 - accuracy: 0.6850 - val_loss: 1.0779 - val_accuracy: 0.5200\n",
      "Epoch 46/50\n",
      "400/400 [==============================] - 0s 67us/sample - loss: 0.7008 - accuracy: 0.6725 - val_loss: 1.1225 - val_accuracy: 0.5200\n",
      "Epoch 47/50\n",
      "400/400 [==============================] - 0s 74us/sample - loss: 0.6735 - accuracy: 0.6950 - val_loss: 1.0749 - val_accuracy: 0.5400\n",
      "Epoch 48/50\n",
      "400/400 [==============================] - 0s 70us/sample - loss: 0.6795 - accuracy: 0.6850 - val_loss: 1.1304 - val_accuracy: 0.4900\n",
      "Epoch 49/50\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 0.6830 - accuracy: 0.6750 - val_loss: 1.1189 - val_accuracy: 0.5200\n",
      "Epoch 50/50\n",
      "400/400 [==============================] - 0s 72us/sample - loss: 0.6855 - accuracy: 0.6800 - val_loss: 1.0956 - val_accuracy: 0.5300\n",
      "*****Transferring done***** Trainable: True\n"
     ]
    }
   ],
   "source": [
    "MA_to_NY = TransferLearn(fromState = \"MA\", toState = \"NY\", layers_to_transfer=2, verbose = 1)\n",
    "MA_to_NY.initFromStateData()\n",
    "MA_to_NY.initToStateData(500)\n",
    "compareMAandNY = MA_to_NY.compare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.00999999, -0.00999999)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compareMAandNY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['NC', 'WI', 'NY', 'MD', 'PA', 'CA', 'TX', 'AZ', 'WA', 'IL', 'KY', 'MT', 'IA', 'GA', 'ME', 'VA', 'SC', 'WV', 'FL', 'NH', 'MN', 'NE', 'AR', 'NJ', 'SD', 'NM', 'OK', 'MI', 'VT', 'ID', 'DE', 'MA', 'WY', 'CO', 'IN', 'AL', 'TN', 'HI', 'AK', 'OH', 'RI', 'LA', 'OR', 'KS', 'UT', 'MO', 'DC', 'NV', 'ND', 'MS', 'CT'])\n"
     ]
    }
   ],
   "source": [
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = [\"MA\", \"NY\", \"AK\", \"CO\"]\n",
    "I,J = len(states), len(states)\n",
    "similarity_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layers_to_transfer = 4\n",
    "# similarity_list.append(np.zeros((2,I,J)))\n",
    "# #We can only transfer at most 4 layers for now\n",
    "# for n in range(1,layers_to_transfer + 1):\n",
    "#     #n of IxJ matrices\n",
    "#     similarity = np.zeros((2,I,J))\n",
    "#     for r in range(I):\n",
    "#         fromState = states[r]\n",
    "#         for c in range(J):\n",
    "#             toState = states[c]\n",
    "#             print(\"Processing\", fromState, toState, \"layers transferred:\", n)\n",
    "#             if fromState != toState:\n",
    "#                 transferLearner = TransferLearn(fromStateData = data[fromState], toStateData = data[toState], layers_to_transfer=n,verbose=0)\n",
    "#                 frozen_diff, unfrozen_diff = transferLearner.compare()\n",
    "#             else:\n",
    "#                 frozen_diff, unfrozen_diff = 0, 0\n",
    "#             similarity[0][r][c] = frozen_diff\n",
    "#             similarity[1][r][c] = unfrozen_diff\n",
    "#     print(similarity)\n",
    "#     similarity_list.append(similarity)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(similarity_list)):\n",
    "#     print(\"Transferred\",i,\"layers:\")\n",
    "#     print(similarity_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing MA MA layers transferred: 1\n",
      "Processing MA NY layers transferred: 1\n",
      "*****Training Benchmark Model*****\n",
      "*****Training Benchmark Model Done*****\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: False\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: True\n",
      "Processing MA AK layers transferred: 1\n",
      "*****Training Benchmark Model*****\n",
      "*****Training Benchmark Model Done*****\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: False\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: True\n",
      "Processing MA CO layers transferred: 1\n",
      "*****Training Benchmark Model*****\n",
      "*****Training Benchmark Model Done*****\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: False\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: True\n",
      "Processing NY MA layers transferred: 1\n",
      "*****Training Benchmark Model*****\n",
      "*****Training Benchmark Model Done*****\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: False\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: True\n",
      "Processing NY NY layers transferred: 1\n",
      "Processing NY AK layers transferred: 1\n",
      "*****Training Benchmark Model*****\n",
      "*****Training Benchmark Model Done*****\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: False\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: True\n",
      "Processing NY CO layers transferred: 1\n",
      "*****Training Benchmark Model*****\n",
      "*****Training Benchmark Model Done*****\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: False\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: True\n",
      "Processing AK MA layers transferred: 1\n",
      "*****Training Benchmark Model*****\n",
      "*****Training Benchmark Model Done*****\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: False\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: True\n",
      "Processing AK NY layers transferred: 1\n",
      "*****Training Benchmark Model*****\n",
      "*****Training Benchmark Model Done*****\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: False\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: True\n",
      "Processing AK AK layers transferred: 1\n",
      "Processing AK CO layers transferred: 1\n",
      "*****Training Benchmark Model*****\n",
      "*****Training Benchmark Model Done*****\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: False\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: True\n",
      "Processing CO MA layers transferred: 1\n",
      "*****Training Benchmark Model*****\n",
      "*****Training Benchmark Model Done*****\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: False\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: True\n",
      "Processing CO NY layers transferred: 1\n",
      "*****Training Benchmark Model*****\n",
      "*****Training Benchmark Model Done*****\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: False\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: True\n",
      "Processing CO AK layers transferred: 1\n",
      "*****Training Benchmark Model*****\n",
      "*****Training Benchmark Model Done*****\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: False\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: True\n",
      "Processing CO CO layers transferred: 1\n",
      "[[[ 0.          0.02000004  0.00999999  0.        ]\n",
      "  [-0.01999998  0.          0.         -0.00999999]\n",
      "  [-0.01000005  0.          0.          0.00999999]\n",
      "  [-0.03000003 -0.01999998  0.05000001  0.        ]]\n",
      "\n",
      " [[ 0.          0.01000005 -0.03000003 -0.01000005]\n",
      "  [-0.00999999  0.          0.00999999 -0.00999999]\n",
      "  [-0.02000004  0.01999998  0.         -0.00999999]\n",
      "  [-0.04000002 -0.01999998  0.05000001  0.        ]]]\n",
      "Processing MA MA layers transferred: 2\n",
      "Processing MA NY layers transferred: 2\n",
      "*****Training Benchmark Model*****\n",
      "*****Training Benchmark Model Done*****\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: False\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: True\n",
      "Processing MA AK layers transferred: 2\n",
      "*****Training Benchmark Model*****\n",
      "*****Training Benchmark Model Done*****\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: False\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: True\n",
      "Processing MA CO layers transferred: 2\n",
      "*****Training Benchmark Model*****\n",
      "*****Training Benchmark Model Done*****\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: False\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: True\n",
      "Processing NY MA layers transferred: 2\n",
      "*****Training Benchmark Model*****\n",
      "*****Training Benchmark Model Done*****\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: False\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: True\n",
      "Processing NY NY layers transferred: 2\n",
      "Processing NY AK layers transferred: 2\n",
      "*****Training Benchmark Model*****\n",
      "*****Training Benchmark Model Done*****\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: False\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: True\n",
      "Processing NY CO layers transferred: 2\n",
      "*****Training Benchmark Model*****\n",
      "*****Training Benchmark Model Done*****\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: False\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: True\n",
      "Processing AK MA layers transferred: 2\n",
      "*****Training Benchmark Model*****\n",
      "*****Training Benchmark Model Done*****\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: False\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: True\n",
      "Processing AK NY layers transferred: 2\n",
      "*****Training Benchmark Model*****\n",
      "*****Training Benchmark Model Done*****\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: False\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: True\n",
      "Processing AK AK layers transferred: 2\n",
      "Processing AK CO layers transferred: 2\n",
      "*****Training Benchmark Model*****\n",
      "*****Training Benchmark Model Done*****\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: False\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: True\n",
      "Processing CO MA layers transferred: 2\n",
      "*****Training Benchmark Model*****\n",
      "*****Training Benchmark Model Done*****\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: False\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: True\n",
      "Processing CO NY layers transferred: 2\n",
      "*****Training Benchmark Model*****\n",
      "*****Training Benchmark Model Done*****\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: False\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: True\n",
      "Processing CO AK layers transferred: 2\n",
      "*****Training Benchmark Model*****\n",
      "*****Training Benchmark Model Done*****\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Transferring done***** Trainable: False\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: True\n",
      "Processing CO CO layers transferred: 2\n",
      "[[[ 0.          0.04000002  0.02000004 -0.00999999]\n",
      "  [ 0.03999996  0.          0.00999999  0.01000005]\n",
      "  [ 0.04000002  0.02999997  0.         -0.00999999]\n",
      "  [-0.01999998  0.          0.04000002  0.        ]]\n",
      "\n",
      " [[ 0.          0.09000003  0.         -0.05000001]\n",
      "  [ 0.02999997  0.          0.05000001  0.04000002]\n",
      "  [ 0.04000002  0.06999996  0.         -0.01999998]\n",
      "  [-0.02999997  0.00999999  0.          0.        ]]]\n",
      "Processing MA MA layers transferred: 3\n",
      "Processing MA NY layers transferred: 3\n",
      "*****Training Benchmark Model*****\n",
      "*****Training Benchmark Model Done*****\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: False\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: True\n",
      "Processing MA AK layers transferred: 3\n",
      "*****Training Benchmark Model*****\n",
      "*****Training Benchmark Model Done*****\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: False\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: True\n",
      "Processing MA CO layers transferred: 3\n",
      "*****Training Benchmark Model*****\n",
      "*****Training Benchmark Model Done*****\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: False\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: True\n",
      "Processing NY MA layers transferred: 3\n",
      "*****Training Benchmark Model*****\n",
      "*****Training Benchmark Model Done*****\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: False\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: True\n",
      "Processing NY NY layers transferred: 3\n",
      "Processing NY AK layers transferred: 3\n",
      "*****Training Benchmark Model*****\n",
      "*****Training Benchmark Model Done*****\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: False\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: True\n",
      "Processing NY CO layers transferred: 3\n",
      "*****Training Benchmark Model*****\n",
      "*****Training Benchmark Model Done*****\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: False\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: True\n",
      "Processing AK MA layers transferred: 3\n",
      "*****Training Benchmark Model*****\n",
      "*****Training Benchmark Model Done*****\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: False\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: True\n",
      "Processing AK NY layers transferred: 3\n",
      "*****Training Benchmark Model*****\n",
      "*****Training Benchmark Model Done*****\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: False\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: True\n",
      "Processing AK AK layers transferred: 3\n",
      "Processing AK CO layers transferred: 3\n",
      "*****Training Benchmark Model*****\n",
      "*****Training Benchmark Model Done*****\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: False\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: True\n",
      "Processing CO MA layers transferred: 3\n",
      "*****Training Benchmark Model*****\n",
      "*****Training Benchmark Model Done*****\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: False\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: True\n",
      "Processing CO NY layers transferred: 3\n",
      "*****Training Benchmark Model*****\n",
      "*****Training Benchmark Model Done*****\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: False\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: True\n",
      "Processing CO AK layers transferred: 3\n",
      "*****Training Benchmark Model*****\n",
      "*****Training Benchmark Model Done*****\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: False\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: True\n",
      "Processing CO CO layers transferred: 3\n",
      "[[[ 0.         -0.00999999 -0.01999998 -0.01999998]\n",
      "  [-0.01999998  0.          0.         -0.06      ]\n",
      "  [-0.01000005 -0.01999998  0.         -0.06      ]\n",
      "  [ 0.01000005 -0.00999999 -0.06999999  0.        ]]\n",
      "\n",
      " [[ 0.          0.07000002  0.00999999  0.03000003]\n",
      "  [-0.01999998  0.         -0.03000003 -0.04000002]\n",
      "  [-0.05000001  0.05000001  0.         -0.03999996]\n",
      "  [-0.03999996  0.00999999 -0.06999999  0.        ]]]\n"
     ]
    }
   ],
   "source": [
    "layers_to_transfer = 3\n",
    "similarity_list.append(np.zeros((2,I,J)))\n",
    "#We can only transfer at most 4 layers for now\n",
    "for n in range(1,layers_to_transfer + 1):\n",
    "    #n of IxJ matrices\n",
    "    similarity = np.zeros((2,I,J))\n",
    "    for r in range(I):\n",
    "        fromState = states[r]\n",
    "        transferLearner = TransferLearn(fromState = fromState, toState = None, layers_to_transfer=n,verbose=0)\n",
    "        transferLearner.initFromStateData()\n",
    "        transferLearner.getFromModelWeights()\n",
    "        for c in range(J):\n",
    "            toState = states[c]\n",
    "            print(\"Processing\", fromState, toState, \"layers transferred:\", n)\n",
    "            if fromState != toState:\n",
    "                transferLearner.toState = toState\n",
    "                transferLearner.initToStateData(sample_size=500)\n",
    "                frozen_diff, unfrozen_diff = transferLearner.compare()\n",
    "            else:\n",
    "                frozen_diff, unfrozen_diff = 0, 0\n",
    "            similarity[0][r][c] = frozen_diff\n",
    "            similarity[1][r][c] = unfrozen_diff\n",
    "    print(similarity)\n",
    "    similarity_list.append(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transferred 0 layers:\n",
      "[[[0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]]]\n",
      "Transferred 1 layers:\n",
      "[[[ 0.          0.02000004  0.00999999  0.        ]\n",
      "  [-0.01999998  0.          0.         -0.00999999]\n",
      "  [-0.01000005  0.          0.          0.00999999]\n",
      "  [-0.03000003 -0.01999998  0.05000001  0.        ]]\n",
      "\n",
      " [[ 0.          0.01000005 -0.03000003 -0.01000005]\n",
      "  [-0.00999999  0.          0.00999999 -0.00999999]\n",
      "  [-0.02000004  0.01999998  0.         -0.00999999]\n",
      "  [-0.04000002 -0.01999998  0.05000001  0.        ]]]\n",
      "Transferred 2 layers:\n",
      "[[[ 0.          0.04000002  0.02000004 -0.00999999]\n",
      "  [ 0.03999996  0.          0.00999999  0.01000005]\n",
      "  [ 0.04000002  0.02999997  0.         -0.00999999]\n",
      "  [-0.01999998  0.          0.04000002  0.        ]]\n",
      "\n",
      " [[ 0.          0.09000003  0.         -0.05000001]\n",
      "  [ 0.02999997  0.          0.05000001  0.04000002]\n",
      "  [ 0.04000002  0.06999996  0.         -0.01999998]\n",
      "  [-0.02999997  0.00999999  0.          0.        ]]]\n",
      "Transferred 3 layers:\n",
      "[[[ 0.         -0.00999999 -0.01999998 -0.01999998]\n",
      "  [-0.01999998  0.          0.         -0.06      ]\n",
      "  [-0.01000005 -0.01999998  0.         -0.06      ]\n",
      "  [ 0.01000005 -0.00999999 -0.06999999  0.        ]]\n",
      "\n",
      " [[ 0.          0.07000002  0.00999999  0.03000003]\n",
      "  [-0.01999998  0.         -0.03000003 -0.04000002]\n",
      "  [-0.05000001  0.05000001  0.         -0.03999996]\n",
      "  [-0.03999996  0.00999999 -0.06999999  0.        ]]]\n"
     ]
    }
   ],
   "source": [
    "#run 1\n",
    "for i in range(len(similarity_list)):\n",
    "    print(\"Transferred\",i,\"layers:\")\n",
    "    print(similarity_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "frozen_similarity_list = [m[0] for m in similarity_list]\n",
    "unfrozen_similarity_list = [m[1] for m in similarity_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]]),\n",
       " array([[ 0.        ,  0.02000004,  0.00999999,  0.        ],\n",
       "        [-0.01999998,  0.        ,  0.        , -0.00999999],\n",
       "        [-0.01000005,  0.        ,  0.        ,  0.00999999],\n",
       "        [-0.03000003, -0.01999998,  0.05000001,  0.        ]]),\n",
       " array([[ 0.        ,  0.04000002,  0.02000004, -0.00999999],\n",
       "        [ 0.03999996,  0.        ,  0.00999999,  0.01000005],\n",
       "        [ 0.04000002,  0.02999997,  0.        , -0.00999999],\n",
       "        [-0.01999998,  0.        ,  0.04000002,  0.        ]]),\n",
       " array([[ 0.        , -0.00999999, -0.01999998, -0.01999998],\n",
       "        [-0.01999998,  0.        ,  0.        , -0.06      ],\n",
       "        [-0.01000005, -0.01999998,  0.        , -0.06      ],\n",
       "        [ 0.01000005, -0.00999999, -0.06999999,  0.        ]])]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frozen_similarity_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]]),\n",
       " array([[ 0.        ,  0.01000005, -0.03000003, -0.01000005],\n",
       "        [-0.00999999,  0.        ,  0.00999999, -0.00999999],\n",
       "        [-0.02000004,  0.01999998,  0.        , -0.00999999],\n",
       "        [-0.04000002, -0.01999998,  0.05000001,  0.        ]]),\n",
       " array([[ 0.        ,  0.09000003,  0.        , -0.05000001],\n",
       "        [ 0.02999997,  0.        ,  0.05000001,  0.04000002],\n",
       "        [ 0.04000002,  0.06999996,  0.        , -0.01999998],\n",
       "        [-0.02999997,  0.00999999,  0.        ,  0.        ]]),\n",
       " array([[ 0.        ,  0.07000002,  0.00999999,  0.03000003],\n",
       "        [-0.01999998,  0.        , -0.03000003, -0.04000002],\n",
       "        [-0.05000001,  0.05000001,  0.        , -0.03999996],\n",
       "        [-0.03999996,  0.00999999, -0.06999999,  0.        ]])]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unfrozen_similarity_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "frozen_max_similarity_matrix = np.maximum.reduce(frozen_similarity_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.04000002, 0.02000004, 0.        ],\n",
       "       [0.03999996, 0.        , 0.00999999, 0.01000005],\n",
       "       [0.04000002, 0.02999997, 0.        , 0.00999999],\n",
       "       [0.01000005, 0.        , 0.05000001, 0.        ]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frozen_max_similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfrozen_max_similarity_matrix = np.maximum.reduce(unfrozen_similarity_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.09000003, 0.00999999, 0.03000003],\n",
       "       [0.02999997, 0.        , 0.05000001, 0.04000002],\n",
       "       [0.04000002, 0.06999996, 0.        , 0.        ],\n",
       "       [0.        , 0.00999999, 0.05000001, 0.        ]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unfrozen_max_similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
