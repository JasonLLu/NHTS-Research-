{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "#tf.enable_eager_execution()\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('encodedStates.pickle', 'rb') as handle:\n",
    "    data = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_np(dataframe,shuffle=True,batch_size=32,target=\"HHVEHCNT\"):\n",
    "    dataframe = dataframe.copy()\n",
    "    labels = dataframe.pop(target)\n",
    "    return dataframe.values, labels.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransferLearn:\n",
    "    \n",
    "    def __init__(self, fromStateData, toStateData, layers_to_transfer, verbose):\n",
    "        self.data = data\n",
    "        self.fromState = fromStateData\n",
    "        self.toState = toStateData\n",
    "        self.layers_to_transfer = layers_to_transfer\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        self.fromModelWeights = None\n",
    "        \n",
    "        self.train_X_from, self.train_y_from = df_to_np(fromStateData)\n",
    "        self.train_X_to, self.train_y_to = df_to_np(toStateData)\n",
    "    \n",
    "    #Get the weights from model built on toStateData\n",
    "    def getFromModelWeights(self, batch_size=100, validation_split=0.2, epochs=5):\n",
    "        train_X_from = self.train_X_from.copy()\n",
    "        train_y_from = self.train_y_from.copy()\n",
    "        model = tf.keras.Sequential([\n",
    "          tf.keras.layers.Dense(128,activation=\"relu\"),\n",
    "          tf.keras.layers.Dense(128),\n",
    "          tf.keras.layers.Dense(128),\n",
    "          tf.keras.layers.Dense(128),\n",
    "          tf.keras.layers.Dense(64,activation=\"relu\"),\n",
    "          tf.keras.layers.Dense(4,activation=\"softmax\")\n",
    "        ])\n",
    "        \n",
    "        model.compile(optimizer='adam',\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        model.fit(x=train_X_from, y = train_y_from,epochs=5, batch_size = batch_size, validation_split=validation_split, shuffle=True, verbose=self.verbose)\n",
    "        \n",
    "        weights = []\n",
    "        for i in range(0,self.layers_to_transfer):\n",
    "            weights.append(model.layers[i].get_weights())\n",
    "        self.fromModelWeights = weights\n",
    "        return self.fromModelWeights\n",
    "    \n",
    "    def transfer(self, trainable=True, batch_size=100, validation_split=0.2, epochs=5):\n",
    "        train_X_to = self.train_X_to.copy()\n",
    "        train_y_to = self.train_y_to.copy()\n",
    "        weights = self.fromModelWeights if self.fromModelWeights else self.getFromModelWeights()\n",
    "        print(\"*****weights obtained from fromStateData*****\")\n",
    "        \n",
    "        print(\"Transferring\")\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(128,activation=\"relu\", weights=weights[0], trainable=trainable))\n",
    "        for i in range(1,self.layers_to_transfer):\n",
    "            model.add(tf.keras.layers.Dense(128, weights=weights[i], trainable=trainable))\n",
    "        for i in range(4-self.layers_to_transfer,4):\n",
    "            model.add(tf.keras.layers.Dense(128))\n",
    "        model.add(tf.keras.layers.Dense(64,activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.Dense(4,activation=\"softmax\"))\n",
    "\n",
    "        \n",
    "        model.compile(optimizer='adam',\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "        history = model.fit(x=train_X_to, y = train_y_to, epochs=epochs, batch_size = batch_size, validation_split=validation_split, shuffle=True,verbose=self.verbose)\n",
    "        val_acc = history.history[\"val_accuracy\"][-1]\n",
    "        print(\"*****Transferring done*****\", \"Trainable:\", trainable)\n",
    "        return model, val_acc\n",
    "    \n",
    "    \n",
    "    def benchmark(self, batch_size=100, validation_split=0.2, epochs=5):\n",
    "        train_X_to = self.train_X_to.copy()\n",
    "        train_y_to = self.train_y_to.copy()\n",
    "        print(\"*****Training Benchmark Model*****\")\n",
    "        model = tf.keras.Sequential([\n",
    "          tf.keras.layers.Dense(128,activation=\"relu\"),\n",
    "          tf.keras.layers.Dense(128),\n",
    "          tf.keras.layers.Dense(128),\n",
    "          tf.keras.layers.Dense(128),\n",
    "          tf.keras.layers.Dense(64,activation=\"relu\"),\n",
    "          tf.keras.layers.Dense(4,activation=\"softmax\")\n",
    "        ])\n",
    "        \n",
    "        model.compile(optimizer='adam',\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        history = model.fit(x=train_X_to, y = train_y_to,epochs=5, batch_size = batch_size, validation_split=validation_split, shuffle=True,verbose=self.verbose)\n",
    "        val_acc = history.history[\"val_accuracy\"][-1]\n",
    "        print(\"*****Training Benchmark Model Done*****\")\n",
    "        return model, val_acc\n",
    "    \n",
    "    def compare(self):\n",
    "        benchmark_model, benchmark_acc = self.benchmark()\n",
    "        frozenTransfer_model, frozenTransfer_acc = self.transfer(trainable=False)\n",
    "        unfrozenTransfer_model, unfrozenTransfer_acc = self.transfer(trainable=True)\n",
    "        \n",
    "        return (benchmark_acc-frozenTransfer_acc, benchmark_acc-unfrozenTransfer_acc)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Training Benchmark Model*****\n",
      "Train on 81690 samples, validate on 20423 samples\n",
      "Epoch 1/5\n",
      "81690/81690 [==============================] - 3s 42us/sample - loss: 0.9444 - accuracy: 0.5803 - val_loss: 0.9443 - val_accuracy: 0.5956\n",
      "Epoch 2/5\n",
      "81690/81690 [==============================] - 3s 31us/sample - loss: 0.9236 - accuracy: 0.5918 - val_loss: 0.9482 - val_accuracy: 0.5947\n",
      "Epoch 3/5\n",
      "81690/81690 [==============================] - 3s 31us/sample - loss: 0.9196 - accuracy: 0.5950 - val_loss: 0.9456 - val_accuracy: 0.5901\n",
      "Epoch 4/5\n",
      "81690/81690 [==============================] - 3s 36us/sample - loss: 0.9175 - accuracy: 0.5952 - val_loss: 0.9402 - val_accuracy: 0.5958\n",
      "Epoch 5/5\n",
      "81690/81690 [==============================] - 3s 32us/sample - loss: 0.9151 - accuracy: 0.5971 - val_loss: 0.9555 - val_accuracy: 0.5971\n",
      "*****Training Benchmark Model Done*****\n",
      "Train on 2568 samples, validate on 643 samples\n",
      "Epoch 1/5\n",
      "2568/2568 [==============================] - 1s 291us/sample - loss: 1.0529 - accuracy: 0.5541 - val_loss: 1.0475 - val_accuracy: 0.5583\n",
      "Epoch 2/5\n",
      "2568/2568 [==============================] - 0s 40us/sample - loss: 0.8478 - accuracy: 0.6597 - val_loss: 1.0383 - val_accuracy: 0.5754\n",
      "Epoch 3/5\n",
      "2568/2568 [==============================] - 0s 41us/sample - loss: 0.7923 - accuracy: 0.6986 - val_loss: 1.0916 - val_accuracy: 0.5303\n",
      "Epoch 4/5\n",
      "2568/2568 [==============================] - 0s 39us/sample - loss: 0.7430 - accuracy: 0.7033 - val_loss: 1.1400 - val_accuracy: 0.5739\n",
      "Epoch 5/5\n",
      "2568/2568 [==============================] - 0s 41us/sample - loss: 0.7177 - accuracy: 0.7052 - val_loss: 1.1215 - val_accuracy: 0.5708\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "Train on 81690 samples, validate on 20423 samples\n",
      "Epoch 1/5\n",
      "81690/81690 [==============================] - 3s 35us/sample - loss: 0.9372 - accuracy: 0.5839 - val_loss: 0.9469 - val_accuracy: 0.5928\n",
      "Epoch 2/5\n",
      "81690/81690 [==============================] - 2s 30us/sample - loss: 0.9229 - accuracy: 0.5922 - val_loss: 0.9422 - val_accuracy: 0.5979\n",
      "Epoch 3/5\n",
      "81690/81690 [==============================] - 3s 31us/sample - loss: 0.9202 - accuracy: 0.5942 - val_loss: 0.9452 - val_accuracy: 0.5878\n",
      "Epoch 4/5\n",
      "81690/81690 [==============================] - 3s 31us/sample - loss: 0.9189 - accuracy: 0.5957 - val_loss: 0.9468 - val_accuracy: 0.5893\n",
      "Epoch 5/5\n",
      "81690/81690 [==============================] - 3s 32us/sample - loss: 0.9167 - accuracy: 0.5955 - val_loss: 0.9499 - val_accuracy: 0.5945\n",
      "*****Transferring done***** Trainable: False\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "Train on 81690 samples, validate on 20423 samples\n",
      "Epoch 1/5\n",
      "81690/81690 [==============================] - 3s 40us/sample - loss: 0.9357 - accuracy: 0.5842 - val_loss: 0.9463 - val_accuracy: 0.5852\n",
      "Epoch 2/5\n",
      "81690/81690 [==============================] - 3s 33us/sample - loss: 0.9222 - accuracy: 0.5912 - val_loss: 0.9603 - val_accuracy: 0.5936\n",
      "Epoch 3/5\n",
      "81690/81690 [==============================] - 3s 33us/sample - loss: 0.9178 - accuracy: 0.5962 - val_loss: 0.9455 - val_accuracy: 0.5989\n",
      "Epoch 4/5\n",
      "81690/81690 [==============================] - 3s 33us/sample - loss: 0.9153 - accuracy: 0.5981 - val_loss: 0.9438 - val_accuracy: 0.5900\n",
      "Epoch 5/5\n",
      "81690/81690 [==============================] - 3s 32us/sample - loss: 0.9135 - accuracy: 0.5982 - val_loss: 0.9487 - val_accuracy: 0.5895\n",
      "*****Transferring done***** Trainable: True\n"
     ]
    }
   ],
   "source": [
    "MA_to_NY = TransferLearn(fromStateData = data[\"MA\"], toStateData = data[\"NY\"], layers_to_transfer=2, verbose = 1)\n",
    "compareMAandNY = MA_to_NY.compare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.002644062, 0.0076384544)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compareMAandNY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['NC', 'WI', 'NY', 'MD', 'PA', 'CA', 'TX', 'AZ', 'WA', 'IL', 'KY', 'MT', 'IA', 'GA', 'ME', 'VA', 'SC', 'WV', 'FL', 'NH', 'MN', 'NE', 'AR', 'NJ', 'SD', 'NM', 'OK', 'MI', 'VT', 'ID', 'DE', 'MA', 'WY', 'CO', 'IN', 'AL', 'TN', 'HI', 'AK', 'OH', 'RI', 'LA', 'OR', 'KS', 'UT', 'MO', 'DC', 'NV', 'ND', 'MS', 'CT'])\n"
     ]
    }
   ],
   "source": [
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = [\"MA\", \"CA\", \"NY\"]\n",
    "I,J = len(states), len(states)\n",
    "similarity_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing MA MA layers transferred: 1\n",
      "Processing MA CA layers transferred: 1\n",
      "*****Training Benchmark Model*****\n",
      "*****Training Benchmark Model Done*****\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: False\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: True\n",
      "Processing MA NY layers transferred: 1\n",
      "*****Training Benchmark Model*****\n",
      "*****Training Benchmark Model Done*****\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: False\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: True\n",
      "Processing CA MA layers transferred: 1\n",
      "*****Training Benchmark Model*****\n",
      "*****Training Benchmark Model Done*****\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: False\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: True\n",
      "Processing CA CA layers transferred: 1\n",
      "Processing CA NY layers transferred: 1\n",
      "*****Training Benchmark Model*****\n",
      "*****Training Benchmark Model Done*****\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: False\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: True\n",
      "Processing NY MA layers transferred: 1\n",
      "*****Training Benchmark Model*****\n",
      "*****Training Benchmark Model Done*****\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: False\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: True\n",
      "Processing NY CA layers transferred: 1\n",
      "*****Training Benchmark Model*****\n",
      "*****Training Benchmark Model Done*****\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: False\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: True\n",
      "Processing NY NY layers transferred: 1\n",
      "[[[ 0.          0.00743616 -0.00063652]\n",
      "  [ 0.01244169  0.         -0.0251677 ]\n",
      "  [-0.01088649  0.00227571  0.        ]]\n",
      "\n",
      " [[ 0.          0.00278854  0.00088137]\n",
      "  [ 0.01244169  0.         -0.02536356]\n",
      "  [-0.01088649 -0.00192314  0.        ]]]\n",
      "Processing MA MA layers transferred: 2\n",
      "Processing MA CA layers transferred: 2\n",
      "*****Training Benchmark Model*****\n",
      "*****Training Benchmark Model Done*****\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: False\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: True\n",
      "Processing MA NY layers transferred: 2\n",
      "*****Training Benchmark Model*****\n",
      "*****Training Benchmark Model Done*****\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: False\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: True\n",
      "Processing CA MA layers transferred: 2\n",
      "*****Training Benchmark Model*****\n",
      "*****Training Benchmark Model Done*****\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: False\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: True\n",
      "Processing CA CA layers transferred: 2\n",
      "Processing CA NY layers transferred: 2\n",
      "*****Training Benchmark Model*****\n",
      "*****Training Benchmark Model Done*****\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: False\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: True\n",
      "Processing NY MA layers transferred: 2\n",
      "*****Training Benchmark Model*****\n",
      "*****Training Benchmark Model Done*****\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: False\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: True\n",
      "Processing NY CA layers transferred: 2\n",
      "*****Training Benchmark Model*****\n",
      "*****Training Benchmark Model Done*****\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: False\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: True\n",
      "Processing NY NY layers transferred: 2\n",
      "[[[ 0.          0.0048399   0.00665915]\n",
      "  [-0.0279938   0.         -0.00225234]\n",
      "  [ 0.02021772 -0.01631463  0.        ]]\n",
      "\n",
      " [[ 0.          0.00608993  0.00014687]\n",
      "  [ 0.01866251  0.          0.00053859]\n",
      "  [ 0.0155521  -0.00842977  0.        ]]]\n",
      "Processing MA MA layers transferred: 3\n",
      "Processing MA CA layers transferred: 3\n",
      "*****Training Benchmark Model*****\n",
      "*****Training Benchmark Model Done*****\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: False\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: True\n",
      "Processing MA NY layers transferred: 3\n",
      "*****Training Benchmark Model*****\n",
      "*****Training Benchmark Model Done*****\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: False\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: True\n",
      "Processing CA MA layers transferred: 3\n",
      "*****Training Benchmark Model*****\n",
      "*****Training Benchmark Model Done*****\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: False\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: True\n",
      "Processing CA CA layers transferred: 3\n",
      "Processing CA NY layers transferred: 3\n",
      "*****Training Benchmark Model*****\n",
      "*****Training Benchmark Model Done*****\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: False\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: True\n",
      "Processing NY MA layers transferred: 3\n",
      "*****Training Benchmark Model*****\n",
      "*****Training Benchmark Model Done*****\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: False\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: True\n",
      "Processing NY CA layers transferred: 3\n",
      "*****Training Benchmark Model*****\n",
      "*****Training Benchmark Model Done*****\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: False\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: True\n",
      "Processing NY NY layers transferred: 3\n",
      "[[[ 0.         -0.00522453  0.0012241 ]\n",
      "  [ 0.06220835  0.          0.00254619]\n",
      "  [-0.00622082 -0.00480783  0.        ]]\n",
      "\n",
      " [[ 0.          0.00012821  0.00014687]\n",
      "  [ 0.10575426  0.         -0.00509226]\n",
      "  [-0.00933129 -0.01230806  0.        ]]]\n",
      "Processing MA MA layers transferred: 4\n",
      "Processing MA CA layers transferred: 4\n",
      "*****Training Benchmark Model*****\n",
      "*****Training Benchmark Model Done*****\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: False\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: True\n",
      "Processing MA NY layers transferred: 4\n",
      "*****Training Benchmark Model*****\n",
      "*****Training Benchmark Model Done*****\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: False\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: True\n",
      "Processing CA MA layers transferred: 4\n",
      "*****Training Benchmark Model*****\n",
      "*****Training Benchmark Model Done*****\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: False\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: True\n",
      "Processing CA CA layers transferred: 4\n",
      "Processing CA NY layers transferred: 4\n",
      "*****Training Benchmark Model*****\n",
      "*****Training Benchmark Model Done*****\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: False\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: True\n",
      "Processing NY MA layers transferred: 4\n",
      "*****Training Benchmark Model*****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Training Benchmark Model Done*****\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: False\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: True\n",
      "Processing NY CA layers transferred: 4\n",
      "*****Training Benchmark Model*****\n",
      "*****Training Benchmark Model Done*****\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: False\n",
      "*****weights obtained from fromStateData*****\n",
      "Transferring\n",
      "*****Transferring done***** Trainable: True\n",
      "Processing NY NY layers transferred: 4\n",
      "[[[ 0.00000000e+00 -8.01265240e-04  4.60267067e-03]\n",
      "  [-6.53188229e-02  0.00000000e+00 -3.08471918e-03]\n",
      "  [-1.86625123e-02  9.93609428e-04  0.00000000e+00]]\n",
      "\n",
      " [[ 0.00000000e+00  3.23730707e-03 -8.03011656e-03]\n",
      "  [-2.48833895e-02  0.00000000e+00 -2.00748444e-03]\n",
      "  [ 1.71073079e-02  9.61422920e-05  0.00000000e+00]]]\n"
     ]
    }
   ],
   "source": [
    "layers_to_transfer = 4\n",
    "similarity_list.append(np.zeros((2,I,J)))\n",
    "#We can only transfer at most 4 layers for now\n",
    "for n in range(1,layers_to_transfer + 1):\n",
    "    #n of IxJ matrices\n",
    "    similarity = np.zeros((2,I,J))\n",
    "    for r in range(I):\n",
    "        fromState = states[r]\n",
    "        for c in range(J):\n",
    "            toState = states[c]\n",
    "            print(\"Processing\", fromState, toState, \"layers transferred:\", n)\n",
    "            if fromState != toState:\n",
    "                transferLearner = TransferLearn(fromStateData = data[fromState], toStateData = data[toState], layers_to_transfer=n,verbose=0)\n",
    "                frozen_diff, unfrozen_diff = transferLearner.compare()\n",
    "            else:\n",
    "                frozen_diff, unfrozen_diff = 0, 0\n",
    "            similarity[0][r][c] = frozen_diff\n",
    "            similarity[1][r][c] = unfrozen_diff\n",
    "    print(similarity)\n",
    "    similarity_list.append(similarity)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transferred 0 layers:\n",
      "[[[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]]\n",
      "Transferred 1 layers:\n",
      "[[[ 0.          0.00743616 -0.00063652]\n",
      "  [ 0.01244169  0.         -0.0251677 ]\n",
      "  [-0.01088649  0.00227571  0.        ]]\n",
      "\n",
      " [[ 0.          0.00278854  0.00088137]\n",
      "  [ 0.01244169  0.         -0.02536356]\n",
      "  [-0.01088649 -0.00192314  0.        ]]]\n",
      "Transferred 2 layers:\n",
      "[[[ 0.          0.0048399   0.00665915]\n",
      "  [-0.0279938   0.         -0.00225234]\n",
      "  [ 0.02021772 -0.01631463  0.        ]]\n",
      "\n",
      " [[ 0.          0.00608993  0.00014687]\n",
      "  [ 0.01866251  0.          0.00053859]\n",
      "  [ 0.0155521  -0.00842977  0.        ]]]\n",
      "Transferred 3 layers:\n",
      "[[[ 0.         -0.00522453  0.0012241 ]\n",
      "  [ 0.06220835  0.          0.00254619]\n",
      "  [-0.00622082 -0.00480783  0.        ]]\n",
      "\n",
      " [[ 0.          0.00012821  0.00014687]\n",
      "  [ 0.10575426  0.         -0.00509226]\n",
      "  [-0.00933129 -0.01230806  0.        ]]]\n",
      "Transferred 4 layers:\n",
      "[[[ 0.00000000e+00 -8.01265240e-04  4.60267067e-03]\n",
      "  [-6.53188229e-02  0.00000000e+00 -3.08471918e-03]\n",
      "  [-1.86625123e-02  9.93609428e-04  0.00000000e+00]]\n",
      "\n",
      " [[ 0.00000000e+00  3.23730707e-03 -8.03011656e-03]\n",
      "  [-2.48833895e-02  0.00000000e+00 -2.00748444e-03]\n",
      "  [ 1.71073079e-02  9.61422920e-05  0.00000000e+00]]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(similarity_list)):\n",
    "    print(\"Transferred\",i,\"layers:\")\n",
    "    print(similarity_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
