{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = [\"HHSIZE\"]\n",
    "categ_features = [\"DRIVER\", \"EDUC\", \"URBANSIZE\", \"URBRUR\"]\n",
    "encoded_state_dictionary = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['HHSIZE', 'HHVEHCNT', 'DRIVER_0', 'DRIVER_1', 'EDUC_1', 'EDUC_2',\n",
      "       'EDUC_3', 'EDUC_4', 'EDUC_5', 'URBANSIZE_1', 'URBANSIZE_2',\n",
      "       'URBANSIZE_3', 'URBANSIZE_4', 'URBANSIZE_5', 'URBANSIZE_6', 'URBRUR_1',\n",
      "       'URBRUR_2'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "getEncoderList = pd.read_csv(\"data_input_V1.csv\")\n",
    "target = \"HHVEHCNT\"\n",
    "all_features = num_features + categ_features + [target]\n",
    "encoderList = pd.get_dummies(data=getEncoderList[all_features], columns=categ_features).columns\n",
    "print(encoderList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data, num_features, categ_features, target=\"HHVEHCNT\"):\n",
    "    all_features = num_features + categ_features + [target]\n",
    "    curr = data.copy(deep=True)[all_features]\n",
    "    \n",
    "    curr[target].values[curr[target].values >= 3] = 3\n",
    "    \n",
    "    for num_feature in num_features:\n",
    "        normalizer = preprocessing.StandardScaler(with_mean = False)\n",
    "        np_normalized = normalizer.fit_transform(curr.loc[:,num_feature].values.reshape(-1,1).astype(np.float32))\n",
    "\n",
    "    curr.loc[:,num_feature] = np_normalized\n",
    "    encoded_data = pd.get_dummies(data=curr, columns=categ_features)\n",
    "    encoded_data = encoded_data.reindex(columns=encoderList, fill_value=0)\n",
    "    encoded_data.to_csv(cwd + \"/encoded_data_input_V1_\" + state + \".csv\", index = False)\n",
    "    encoded_state_dictionary[state] = encoded_data\n",
    "    print(state + \" encoded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = ['NC', 'WI', 'NY', 'MD', 'PA', 'CA', 'TX', 'AZ', 'WA', 'IL', 'KY', 'MT', 'IA', 'GA', 'ME', 'VA', 'SC', 'WV', 'FL', 'NH', 'MN', 'NE', 'AR', 'NJ', 'SD', 'NM', 'OK', 'MI', 'VT', 'ID', 'DE', 'MA', 'WY', 'CO', 'IN', 'AL', 'TN', 'HI', 'AK', 'OH', 'RI', 'LA', 'OR', 'KS', 'UT', 'MO', 'DC', 'NV', 'ND', 'MS', 'CT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NC encoded\n",
      "WI encoded\n",
      "NY encoded\n",
      "MD encoded\n",
      "PA encoded\n",
      "CA encoded\n",
      "TX encoded\n",
      "AZ encoded\n",
      "WA encoded\n",
      "IL encoded\n",
      "KY encoded\n",
      "MT encoded\n",
      "IA encoded\n",
      "GA encoded\n",
      "ME encoded\n",
      "VA encoded\n",
      "SC encoded\n",
      "WV encoded\n",
      "FL encoded\n",
      "NH encoded\n",
      "MN encoded\n",
      "NE encoded\n",
      "AR encoded\n",
      "NJ encoded\n",
      "SD encoded\n",
      "NM encoded\n",
      "OK encoded\n",
      "MI encoded\n",
      "VT encoded\n",
      "ID encoded\n",
      "DE encoded\n",
      "MA encoded\n",
      "WY encoded\n",
      "CO encoded\n",
      "IN encoded\n",
      "AL encoded\n",
      "TN encoded\n",
      "HI encoded\n",
      "AK encoded\n",
      "OH encoded\n",
      "RI encoded\n",
      "LA encoded\n",
      "OR encoded\n",
      "KS encoded\n",
      "UT encoded\n",
      "MO encoded\n",
      "DC encoded\n",
      "NV encoded\n",
      "ND encoded\n",
      "MS encoded\n",
      "CT encoded\n"
     ]
    }
   ],
   "source": [
    "for state in states:\n",
    "    data = pd.read_csv(\"stateDataCSV/data_input_V1_\" + state + \".csv\")\n",
    "    preprocess(data, num_features, categ_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('encodedStates.pickle', 'wb') as handle:\n",
    "    pickle.dump(encoded_state_dictionary, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
